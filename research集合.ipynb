{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UQER SDK的DataAPI模块版本由84.0.71升级到84.0.72\n",
      "127807@wmcloud.com 账号登录成功\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import lightgbm as lgb\n",
    "import glob\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from joblib import Parallel, delayed\n",
    "import time\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "import datetime\n",
    "from sklearn.linear_model import Ridge, LinearRegression\n",
    "import uqer\n",
    "from uqer import DataAPI   #优矿api\n",
    "client = uqer.Client(token='18266a7c0ac9f8cdbe00f9b2ecb65f42316a5f78d9cc22ebabcbd923593356e4')\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ticekrToStr(job_sum):\n",
    "    job_sum = job_sum[job_sum.ticker<700000]\n",
    "    job_sum.loc[job_sum.ticker<10,'temp']='00000'\n",
    "    job_sum.loc[(job_sum.ticker<100)&(job_sum.ticker>=10),'temp']='0000'\n",
    "    job_sum.loc[(job_sum.ticker<1000)&(job_sum.ticker>=100),'temp']='000'\n",
    "    job_sum.loc[(job_sum.ticker<10000)&(job_sum.ticker>=1000),'temp']='00'\n",
    "    job_sum.loc[job_sum.temp==job_sum.temp,'ticker'] = job_sum[job_sum.temp==job_sum.temp]['temp']+job_sum[job_sum.temp==job_sum.temp]['ticker'].astype(str)\n",
    "    del job_sum['temp']\n",
    "    job_sum['ticker'] = job_sum['ticker'].astype(str)\n",
    "    return job_sum\n",
    "\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n",
    "\n",
    "class ExcludeExtreme(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.df_median = None\n",
    "        self.df_standard = None\n",
    "\n",
    "    def fit(self, df_columnList):\n",
    "        self.df_median = df_columnList.median()\n",
    "        self.df_standard = df_columnList.apply(lambda x: x - self.df_median[x.name]).abs().median()\n",
    "        return self\n",
    "\n",
    "    def scaller(self, x):\n",
    "        self.di_max = self.df_median[x.name] + 5 * self.df_standard[x.name]\n",
    "        self.di_min = self.df_median[x.name] - 5 * self.df_standard[x.name]\n",
    "        x = x.apply(lambda v: self.di_min if v < self.di_min else v)\n",
    "        x = x.apply(lambda v: self.di_max if v > self.di_max else v)\n",
    "        return x\n",
    "\n",
    "    def transform(self, df_columnList):\n",
    "        df_columnList = df_columnList.apply(self.scaller)\n",
    "        return df_columnList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* alphas_all里的alpha 2017-01-03 -- 2022-04-01\n",
    "\n",
    "* data里的alpha 2022-03-01 -- 2022-06-14\n",
    "\n",
    "* pct1_cal里的data 2022-04-20 -- 2022-07-28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_list = []\n",
    "for num in range(0, 66):\n",
    "    alpha_list.append('alpha_{}'.format(num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>tradeDate</th>\n",
       "      <th>066_alpha_21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-09</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6049511</th>\n",
       "      <td>999</td>\n",
       "      <td>2022-03-28</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6049512</th>\n",
       "      <td>999</td>\n",
       "      <td>2022-03-29</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6049513</th>\n",
       "      <td>999</td>\n",
       "      <td>2022-03-30</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6049514</th>\n",
       "      <td>999</td>\n",
       "      <td>2022-03-31</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6049515</th>\n",
       "      <td>999</td>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6049516 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ticker   tradeDate  066_alpha_21\n",
       "0             1  2017-01-03           NaN\n",
       "1             1  2017-01-04           NaN\n",
       "2             1  2017-01-05           NaN\n",
       "3             1  2017-01-06           NaN\n",
       "4             1  2017-01-09           NaN\n",
       "...         ...         ...           ...\n",
       "6049511     999  2022-03-28           NaN\n",
       "6049512     999  2022-03-29           NaN\n",
       "6049513     999  2022-03-30           NaN\n",
       "6049514     999  2022-03-31           NaN\n",
       "6049515     999  2022-04-01           NaN\n",
       "\n",
       "[6049516 rows x 3 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('alphas_all/066_alpha_21.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(file_loc, f_x, date, thresh):\n",
    "    result_list = []\n",
    "    for name in f_x:\n",
    "        print(name)\n",
    "        alpha = pd.read_csv(file_loc + name + '.csv')\n",
    "        if alpha.columns.values.tolist()[0] == 'date':\n",
    "            alpha = alpha.rename(columns={\"date\": \"tradeDate\"})\n",
    "        if file_loc != 'alphas_all/066_':\n",
    "            alpha = alpha.set_index(['tradeDate']).stack().reset_index().rename(columns={'level_1': 'ticker', 0: name})\n",
    "        else:\n",
    "            col_name = '066_'+name\n",
    "            alpha = alpha.rename(columns={col_name: name})\n",
    "        alpha['ticker'] = alpha['ticker'].astype(np.int64)\n",
    "        if date != '':\n",
    "            alpha = alpha[alpha.tradeDate == date]\n",
    "        alpha = alpha.set_index(['ticker', 'tradeDate'])\n",
    "        alpha = alpha.sort_index(ascending=True)\n",
    "        result_list.append(alpha)\n",
    "    result = pd.concat(result_list, axis=1)\n",
    "    result = result.reset_index()\n",
    "    result = result.dropna(thresh=thresh)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha_0\n",
      "alpha_1\n",
      "alpha_2\n",
      "alpha_3\n",
      "alpha_4\n",
      "alpha_5\n",
      "alpha_6\n",
      "alpha_7\n",
      "alpha_8\n",
      "alpha_9\n",
      "alpha_10\n",
      "alpha_11\n",
      "alpha_12\n",
      "alpha_13\n",
      "alpha_14\n",
      "alpha_15\n",
      "alpha_16\n",
      "alpha_17\n",
      "alpha_18\n",
      "alpha_19\n",
      "alpha_20\n",
      "alpha_21\n",
      "alpha_22\n",
      "alpha_23\n",
      "alpha_24\n",
      "alpha_25\n",
      "alpha_26\n",
      "alpha_27\n",
      "alpha_28\n",
      "alpha_29\n",
      "alpha_30\n",
      "alpha_31\n",
      "alpha_32\n",
      "alpha_33\n",
      "alpha_34\n",
      "alpha_35\n",
      "alpha_36\n",
      "alpha_37\n",
      "alpha_38\n",
      "alpha_39\n",
      "alpha_40\n",
      "alpha_41\n",
      "alpha_42\n",
      "alpha_43\n",
      "alpha_44\n",
      "alpha_45\n",
      "alpha_46\n",
      "alpha_47\n",
      "alpha_48\n",
      "alpha_49\n",
      "alpha_50\n",
      "alpha_51\n",
      "alpha_52\n",
      "alpha_53\n",
      "alpha_54\n",
      "alpha_55\n",
      "alpha_56\n",
      "alpha_57\n",
      "alpha_58\n",
      "alpha_59\n",
      "alpha_60\n",
      "alpha_61\n",
      "alpha_62\n",
      "alpha_63\n",
      "alpha_64\n",
      "alpha_65\n",
      "alpha_0\n",
      "alpha_1\n",
      "alpha_2\n",
      "alpha_3\n",
      "alpha_4\n",
      "alpha_5\n",
      "alpha_6\n",
      "alpha_7\n",
      "alpha_8\n",
      "alpha_9\n",
      "alpha_10\n",
      "alpha_11\n",
      "alpha_12\n",
      "alpha_13\n",
      "alpha_14\n",
      "alpha_15\n",
      "alpha_16\n",
      "alpha_17\n",
      "alpha_18\n",
      "alpha_19\n",
      "alpha_20\n",
      "alpha_21\n",
      "alpha_22\n",
      "alpha_23\n",
      "alpha_24\n",
      "alpha_25\n",
      "alpha_26\n",
      "alpha_27\n",
      "alpha_28\n",
      "alpha_29\n",
      "alpha_30\n",
      "alpha_31\n",
      "alpha_32\n",
      "alpha_33\n",
      "alpha_34\n",
      "alpha_35\n",
      "alpha_36\n",
      "alpha_37\n",
      "alpha_38\n",
      "alpha_39\n",
      "alpha_40\n",
      "alpha_41\n",
      "alpha_42\n",
      "alpha_43\n",
      "alpha_44\n",
      "alpha_45\n",
      "alpha_46\n",
      "alpha_47\n",
      "alpha_48\n",
      "alpha_49\n",
      "alpha_50\n",
      "alpha_51\n",
      "alpha_52\n",
      "alpha_53\n",
      "alpha_54\n",
      "alpha_55\n",
      "alpha_56\n",
      "alpha_57\n",
      "alpha_58\n",
      "alpha_59\n",
      "alpha_60\n",
      "alpha_61\n",
      "alpha_62\n",
      "alpha_63\n",
      "alpha_64\n",
      "alpha_65\n",
      "alpha_0\n",
      "alpha_1\n",
      "alpha_2\n",
      "alpha_3\n",
      "alpha_4\n",
      "alpha_5\n",
      "alpha_6\n",
      "alpha_7\n",
      "alpha_8\n",
      "alpha_9\n",
      "alpha_10\n",
      "alpha_11\n",
      "alpha_12\n",
      "alpha_13\n",
      "alpha_14\n",
      "alpha_15\n",
      "alpha_16\n",
      "alpha_17\n",
      "alpha_18\n",
      "alpha_19\n",
      "alpha_20\n",
      "alpha_21\n",
      "alpha_22\n",
      "alpha_23\n",
      "alpha_24\n",
      "alpha_25\n",
      "alpha_26\n",
      "alpha_27\n",
      "alpha_28\n",
      "alpha_29\n",
      "alpha_30\n",
      "alpha_31\n",
      "alpha_32\n",
      "alpha_33\n",
      "alpha_34\n",
      "alpha_35\n",
      "alpha_36\n",
      "alpha_37\n",
      "alpha_38\n",
      "alpha_39\n",
      "alpha_40\n",
      "alpha_41\n",
      "alpha_42\n",
      "alpha_43\n",
      "alpha_44\n",
      "alpha_45\n",
      "alpha_46\n",
      "alpha_47\n",
      "alpha_48\n",
      "alpha_49\n",
      "alpha_50\n",
      "alpha_51\n",
      "alpha_52\n",
      "alpha_53\n",
      "alpha_54\n",
      "alpha_55\n",
      "alpha_56\n",
      "alpha_57\n",
      "alpha_58\n",
      "alpha_59\n",
      "alpha_60\n",
      "alpha_61\n",
      "alpha_62\n",
      "alpha_63\n",
      "alpha_64\n",
      "alpha_65\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>tradeDate</th>\n",
       "      <th>alpha_0</th>\n",
       "      <th>alpha_1</th>\n",
       "      <th>alpha_2</th>\n",
       "      <th>alpha_3</th>\n",
       "      <th>alpha_4</th>\n",
       "      <th>alpha_5</th>\n",
       "      <th>alpha_6</th>\n",
       "      <th>alpha_7</th>\n",
       "      <th>...</th>\n",
       "      <th>alpha_56</th>\n",
       "      <th>alpha_57</th>\n",
       "      <th>alpha_58</th>\n",
       "      <th>alpha_59</th>\n",
       "      <th>alpha_60</th>\n",
       "      <th>alpha_61</th>\n",
       "      <th>alpha_62</th>\n",
       "      <th>alpha_63</th>\n",
       "      <th>alpha_64</th>\n",
       "      <th>alpha_65</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-23</td>\n",
       "      <td>0.505398</td>\n",
       "      <td>0.92600</td>\n",
       "      <td>0.7334</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2325</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-24</td>\n",
       "      <td>0.503890</td>\n",
       "      <td>0.90800</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2345</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-25</td>\n",
       "      <td>0.505563</td>\n",
       "      <td>0.91850</td>\n",
       "      <td>0.8667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-26</td>\n",
       "      <td>0.503347</td>\n",
       "      <td>0.91100</td>\n",
       "      <td>0.9330</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2462</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-02-03</td>\n",
       "      <td>0.503449</td>\n",
       "      <td>0.90970</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2480</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6049511</th>\n",
       "      <td>689009</td>\n",
       "      <td>2022-03-28</td>\n",
       "      <td>0.520114</td>\n",
       "      <td>0.99100</td>\n",
       "      <td>0.6000</td>\n",
       "      <td>0.3423</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.252</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.627543</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>0.501</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6049512</th>\n",
       "      <td>689009</td>\n",
       "      <td>2022-03-29</td>\n",
       "      <td>0.457299</td>\n",
       "      <td>0.92040</td>\n",
       "      <td>0.6665</td>\n",
       "      <td>0.3572</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.307</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7230</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.072007</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.7666</td>\n",
       "      <td>0.501</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6049513</th>\n",
       "      <td>689009</td>\n",
       "      <td>2022-03-30</td>\n",
       "      <td>0.479480</td>\n",
       "      <td>0.07056</td>\n",
       "      <td>0.7334</td>\n",
       "      <td>0.3591</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.340</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7270</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.882852</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.6665</td>\n",
       "      <td>0.501</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6049514</th>\n",
       "      <td>689009</td>\n",
       "      <td>2022-03-31</td>\n",
       "      <td>0.549231</td>\n",
       "      <td>0.05548</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.3643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.341</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7260</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.042670</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.5670</td>\n",
       "      <td>0.501</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6049515</th>\n",
       "      <td>689009</td>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>0.448930</td>\n",
       "      <td>0.05933</td>\n",
       "      <td>0.8667</td>\n",
       "      <td>0.3694</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7275</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.779562</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.498</td>\n",
       "      <td>0.5330</td>\n",
       "      <td>0.501</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4620912 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ticker   tradeDate   alpha_0  alpha_1  alpha_2  alpha_3  alpha_4  \\\n",
       "14            1  2017-01-23  0.505398  0.92600   0.7334      NaN      NaN   \n",
       "15            1  2017-01-24  0.503890  0.90800   0.8000      NaN      NaN   \n",
       "16            1  2017-01-25  0.505563  0.91850   0.8667      NaN      NaN   \n",
       "17            1  2017-01-26  0.503347  0.91100   0.9330      NaN      NaN   \n",
       "18            1  2017-02-03  0.503449  0.90970   0.8000      NaN      NaN   \n",
       "...         ...         ...       ...      ...      ...      ...      ...   \n",
       "6049511  689009  2022-03-28  0.520114  0.99100   0.6000   0.3423      NaN   \n",
       "6049512  689009  2022-03-29  0.457299  0.92040   0.6665   0.3572      NaN   \n",
       "6049513  689009  2022-03-30  0.479480  0.07056   0.7334   0.3591      NaN   \n",
       "6049514  689009  2022-03-31  0.549231  0.05548   0.8000   0.3643      NaN   \n",
       "6049515  689009  2022-04-01  0.448930  0.05933   0.8667   0.3694      NaN   \n",
       "\n",
       "         alpha_5  alpha_6  alpha_7  ...  alpha_56  alpha_57  alpha_58  \\\n",
       "14           NaN      NaN      NaN  ...    0.2325       NaN       NaN   \n",
       "15           NaN      NaN      NaN  ...    0.2345       NaN       NaN   \n",
       "16           NaN      NaN      NaN  ...    0.2444       NaN       NaN   \n",
       "17           NaN      NaN      NaN  ...    0.2462       NaN       NaN   \n",
       "18           NaN      NaN      NaN  ...    0.2480       NaN       NaN   \n",
       "...          ...      ...      ...  ...       ...       ...       ...   \n",
       "6049511   -1.252      NaN      0.5  ...    0.7256       NaN       NaN   \n",
       "6049512   -1.307      NaN      0.5  ...    0.7230       NaN       NaN   \n",
       "6049513   -1.340      NaN      0.5  ...    0.7270       NaN       NaN   \n",
       "6049514   -1.341      NaN      0.5  ...    0.7260       NaN       NaN   \n",
       "6049515   -1.304      NaN      0.5  ...    0.7275       NaN       NaN   \n",
       "\n",
       "         alpha_59  alpha_60  alpha_61  alpha_62  alpha_63  alpha_64  alpha_65  \n",
       "14            NaN     0.521     0.521       NaN     0.521       NaN    0.5160  \n",
       "15            NaN     0.521     0.521       NaN     0.521       NaN    0.5400  \n",
       "16            NaN     0.521     0.521       NaN     0.521       NaN    0.5320  \n",
       "17            NaN     0.521     0.521       NaN     0.521       NaN    0.5330  \n",
       "18            NaN     0.521     0.521       NaN     0.521       NaN    0.6290  \n",
       "...           ...       ...       ...       ...       ...       ...       ...  \n",
       "6049511  0.627543     0.501     0.498    0.7000     0.501       NaN    0.5835  \n",
       "6049512  0.072007     0.501     0.498    0.7666     0.501       NaN    0.0434  \n",
       "6049513 -4.882852     0.501     0.498    0.6665     0.501       NaN    0.5320  \n",
       "6049514  3.042670     0.501     0.498    0.5670     0.501       NaN    0.5273  \n",
       "6049515  2.779562     0.501     0.498    0.5330     0.501       NaN    0.5400  \n",
       "\n",
       "[4620912 rows x 68 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>tradeDate</th>\n",
       "      <th>alpha_0</th>\n",
       "      <th>alpha_1</th>\n",
       "      <th>alpha_2</th>\n",
       "      <th>alpha_3</th>\n",
       "      <th>alpha_4</th>\n",
       "      <th>alpha_5</th>\n",
       "      <th>alpha_6</th>\n",
       "      <th>alpha_7</th>\n",
       "      <th>...</th>\n",
       "      <th>alpha_56</th>\n",
       "      <th>alpha_57</th>\n",
       "      <th>alpha_58</th>\n",
       "      <th>alpha_59</th>\n",
       "      <th>alpha_60</th>\n",
       "      <th>alpha_61</th>\n",
       "      <th>alpha_62</th>\n",
       "      <th>alpha_63</th>\n",
       "      <th>alpha_64</th>\n",
       "      <th>alpha_65</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-03-28</td>\n",
       "      <td>13.686417</td>\n",
       "      <td>0.804156</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.725534</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.583392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-03-29</td>\n",
       "      <td>14.483306</td>\n",
       "      <td>0.850134</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.723313</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.543409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-03-30</td>\n",
       "      <td>19.058333</td>\n",
       "      <td>0.768527</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.727143</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.532361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-03-31</td>\n",
       "      <td>13.730159</td>\n",
       "      <td>0.768665</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.725906</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.527214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>13.453121</td>\n",
       "      <td>0.719840</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.727352</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.539820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238452</th>\n",
       "      <td>688787</td>\n",
       "      <td>2022-04-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.501730</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500110</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.501730</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.510381</td>\n",
       "      <td>0.501724</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.510381</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238453</th>\n",
       "      <td>688799</td>\n",
       "      <td>2022-04-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.501189</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.218785</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.501196</td>\n",
       "      <td>-105.170906</td>\n",
       "      <td>0.501202</td>\n",
       "      <td>0.501185</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.501211</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238454</th>\n",
       "      <td>689009</td>\n",
       "      <td>2022-04-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500109</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.501000</td>\n",
       "      <td>0.500996</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.501004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238455</th>\n",
       "      <td>689009</td>\n",
       "      <td>2022-04-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500110</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500996</td>\n",
       "      <td>0.500996</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.500996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238456</th>\n",
       "      <td>689009</td>\n",
       "      <td>2022-05-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500111</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.501992</td>\n",
       "      <td>0.500996</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.501992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>237436 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ticker   tradeDate    alpha_0   alpha_1   alpha_2  alpha_3   alpha_4  \\\n",
       "0            1  2022-03-28  13.686417  0.804156  0.600000      NaN  0.511905   \n",
       "1            1  2022-03-29  14.483306  0.850134  0.666667      NaN  0.511905   \n",
       "2            1  2022-03-30  19.058333  0.768527  0.733333      NaN  0.511905   \n",
       "3            1  2022-03-31  13.730159  0.768665  0.800000      NaN  0.511905   \n",
       "4            1  2022-04-01  13.453121  0.719840  0.866667      NaN  0.511905   \n",
       "...        ...         ...        ...       ...       ...      ...       ...   \n",
       "238452  688787  2022-04-29        NaN       NaN       NaN      NaN  0.501730   \n",
       "238453  688799  2022-04-25        NaN       NaN       NaN      NaN  0.501189   \n",
       "238454  689009  2022-04-13        NaN       NaN       NaN      NaN       NaN   \n",
       "238455  689009  2022-04-29        NaN       NaN       NaN      NaN       NaN   \n",
       "238456  689009  2022-05-06        NaN       NaN       NaN      NaN       NaN   \n",
       "\n",
       "        alpha_5  alpha_6   alpha_7  ...  alpha_56  alpha_57  alpha_58  \\\n",
       "0           NaN      NaN  0.500109  ...  0.725534       NaN       NaN   \n",
       "1           NaN      NaN  0.500109  ...  0.723313       NaN       NaN   \n",
       "2           NaN      NaN  0.500109  ...  0.727143       NaN       NaN   \n",
       "3           NaN      NaN  0.500109  ...  0.725906       NaN       NaN   \n",
       "4           NaN      NaN  0.500109  ...  0.727352       NaN       NaN   \n",
       "...         ...      ...       ...  ...       ...       ...       ...   \n",
       "238452      NaN      NaN  0.500110  ...       NaN       NaN  0.501730   \n",
       "238453      NaN      NaN  0.500109  ...  0.218785       NaN  0.501196   \n",
       "238454      NaN      NaN  0.500109  ...       NaN       NaN       NaN   \n",
       "238455      NaN      NaN  0.500110  ...       NaN       NaN       NaN   \n",
       "238456      NaN      NaN  0.500111  ...       NaN       NaN       NaN   \n",
       "\n",
       "          alpha_59  alpha_60  alpha_61  alpha_62  alpha_63  alpha_64  alpha_65  \n",
       "0              NaN  0.511905  0.511905  0.687500  0.511905       NaN  0.583392  \n",
       "1              NaN  0.511905  0.511905  0.647059  0.511905       NaN  0.543409  \n",
       "2              NaN  0.511905  0.511905  0.944444  0.511905       NaN  0.532361  \n",
       "3              NaN  0.511905  0.511905  0.947368  0.511905       NaN  0.527214  \n",
       "4              NaN  0.511905  0.511905  0.950000  0.511905       NaN  0.539820  \n",
       "...            ...       ...       ...       ...       ...       ...       ...  \n",
       "238452         NaN  0.510381  0.501724  0.700000  0.510381       NaN       NaN  \n",
       "238453 -105.170906  0.501202  0.501185  0.033333  0.501211       NaN       NaN  \n",
       "238454         NaN  0.501000  0.500996  0.038462  0.501004       NaN       NaN  \n",
       "238455         NaN  0.500996  0.500996  0.566667  0.500996       NaN       NaN  \n",
       "238456         NaN  0.501992  0.500996  0.566667  0.501992       NaN       NaN  \n",
       "\n",
       "[237436 rows x 68 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>tradeDate</th>\n",
       "      <th>alpha_0</th>\n",
       "      <th>alpha_1</th>\n",
       "      <th>alpha_2</th>\n",
       "      <th>alpha_3</th>\n",
       "      <th>alpha_4</th>\n",
       "      <th>alpha_5</th>\n",
       "      <th>alpha_6</th>\n",
       "      <th>alpha_7</th>\n",
       "      <th>...</th>\n",
       "      <th>alpha_56</th>\n",
       "      <th>alpha_57</th>\n",
       "      <th>alpha_58</th>\n",
       "      <th>alpha_59</th>\n",
       "      <th>alpha_60</th>\n",
       "      <th>alpha_61</th>\n",
       "      <th>alpha_62</th>\n",
       "      <th>alpha_63</th>\n",
       "      <th>alpha_64</th>\n",
       "      <th>alpha_65</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-05-27</td>\n",
       "      <td>165.614230</td>\n",
       "      <td>0.139064</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.509234</td>\n",
       "      <td>0.500111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.728792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.511038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-05-30</td>\n",
       "      <td>391.314305</td>\n",
       "      <td>0.099046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.509118</td>\n",
       "      <td>0.500111</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.517547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-05-31</td>\n",
       "      <td>377.430375</td>\n",
       "      <td>0.128634</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.509003</td>\n",
       "      <td>0.500111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.730888</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.531304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-06-01</td>\n",
       "      <td>511.396318</td>\n",
       "      <td>0.137585</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.508772</td>\n",
       "      <td>0.500111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.734889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.513975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-06-02</td>\n",
       "      <td>850.418869</td>\n",
       "      <td>0.152140</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.509003</td>\n",
       "      <td>0.500111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.731743</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.514942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247445</th>\n",
       "      <td>688778</td>\n",
       "      <td>2022-06-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.501179</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500111</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.501179</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.501193</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.501193</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247446</th>\n",
       "      <td>688779</td>\n",
       "      <td>2022-06-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.501180</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500110</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.501179</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.501188</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.501188</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247447</th>\n",
       "      <td>688786</td>\n",
       "      <td>2022-06-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.504310</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500111</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.504310</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.504348</td>\n",
       "      <td>0.504310</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.504348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247448</th>\n",
       "      <td>688787</td>\n",
       "      <td>2022-06-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.501730</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500111</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.501730</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.503472</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.503472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247449</th>\n",
       "      <td>688819</td>\n",
       "      <td>2022-06-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.501746</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500111</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.501742</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.501754</td>\n",
       "      <td>0.501748</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.501754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>245827 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ticker   tradeDate     alpha_0   alpha_1   alpha_2  alpha_3   alpha_4  \\\n",
       "0            1  2022-05-27  165.614230  0.139064  0.000000      NaN  0.511905   \n",
       "1            1  2022-05-30  391.314305  0.099046  0.000000      NaN  0.511905   \n",
       "2            1  2022-05-31  377.430375  0.128634  0.066667      NaN  0.511905   \n",
       "3            1  2022-06-01  511.396318  0.137585  0.133333      NaN  0.511905   \n",
       "4            1  2022-06-02  850.418869  0.152140  0.000000      NaN  0.511905   \n",
       "...        ...         ...         ...       ...       ...      ...       ...   \n",
       "247445  688778  2022-06-14         NaN       NaN       NaN      NaN  0.501179   \n",
       "247446  688779  2022-06-23         NaN       NaN       NaN      NaN  0.501180   \n",
       "247447  688786  2022-06-13         NaN       NaN       NaN      NaN  0.504310   \n",
       "247448  688787  2022-06-13         NaN       NaN       NaN      NaN  0.501730   \n",
       "247449  688819  2022-06-15         NaN       NaN       NaN      NaN  0.501746   \n",
       "\n",
       "        alpha_5   alpha_6   alpha_7  ...  alpha_56  alpha_57  alpha_58  \\\n",
       "0           NaN  0.509234  0.500111  ...  0.728792       NaN  0.511905   \n",
       "1           NaN  0.509118  0.500111  ...       NaN       NaN  0.511905   \n",
       "2           NaN  0.509003  0.500111  ...  0.730888       NaN  0.511905   \n",
       "3           NaN  0.508772  0.500111  ...  0.734889       NaN  0.511905   \n",
       "4           NaN  0.509003  0.500111  ...  0.731743       NaN  0.511905   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "247445      NaN       NaN  0.500111  ...       NaN       NaN  0.501179   \n",
       "247446      NaN       NaN  0.500110  ...       NaN       NaN  0.501179   \n",
       "247447      NaN       NaN  0.500111  ...       NaN       NaN  0.504310   \n",
       "247448      NaN       NaN  0.500111  ...       NaN       NaN  0.501730   \n",
       "247449      NaN       NaN  0.500111  ...       NaN       NaN  0.501742   \n",
       "\n",
       "        alpha_59  alpha_60  alpha_61  alpha_62  alpha_63  alpha_64  alpha_65  \n",
       "0            NaN  0.511905  0.511905  0.080000  0.511905       NaN  0.511038  \n",
       "1            NaN  0.511905  0.511905  0.038462  0.511905       NaN  0.517547  \n",
       "2            NaN  0.511905  0.511905  0.074074  0.511905       NaN  0.531304  \n",
       "3            NaN  0.511905  0.511905  0.071429  0.511905       NaN  0.513975  \n",
       "4            NaN  0.511905  0.511905  0.034483  0.511905       NaN  0.514942  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "247445       NaN  0.501193  0.500000  0.466667  0.501193       NaN       NaN  \n",
       "247446       NaN  0.501188  0.500000  0.266667  0.501188       NaN       NaN  \n",
       "247447       NaN  0.504348  0.504310  0.466667  0.504348       NaN       NaN  \n",
       "247448       NaN  0.503472  0.500000  0.000000  0.503472       NaN       NaN  \n",
       "247449       NaN  0.501754  0.501748  0.966667  0.501754       NaN       NaN  \n",
       "\n",
       "[245827 rows x 68 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "alphas1 = get_data('alphas_all/066_', alpha_list, '', 20)\n",
    "alphas2 = get_data('data/', alpha_list, '', 20)\n",
    "alphas3 = get_data('pct1_cal/每日预测/data/', alpha_list, '', 20)\n",
    "display(alphas1)\n",
    "display(alphas2)\n",
    "display(alphas3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_data = pd.concat([alphas1, alphas2, alphas3], axis=0)\n",
    "alpha_data = alpha_data.drop_duplicates(subset=['ticker', 'tradeDate'])\n",
    "alpha_data = alpha_data.sort_values(by=['ticker', 'tradeDate']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>tradeDate</th>\n",
       "      <th>alpha_0</th>\n",
       "      <th>alpha_1</th>\n",
       "      <th>alpha_2</th>\n",
       "      <th>alpha_3</th>\n",
       "      <th>alpha_4</th>\n",
       "      <th>alpha_5</th>\n",
       "      <th>alpha_6</th>\n",
       "      <th>alpha_7</th>\n",
       "      <th>...</th>\n",
       "      <th>alpha_56</th>\n",
       "      <th>alpha_57</th>\n",
       "      <th>alpha_58</th>\n",
       "      <th>alpha_59</th>\n",
       "      <th>alpha_60</th>\n",
       "      <th>alpha_61</th>\n",
       "      <th>alpha_62</th>\n",
       "      <th>alpha_63</th>\n",
       "      <th>alpha_64</th>\n",
       "      <th>alpha_65</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-23</td>\n",
       "      <td>0.505398</td>\n",
       "      <td>0.926000</td>\n",
       "      <td>0.733400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.521000</td>\n",
       "      <td>0.521000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.521000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.516000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-24</td>\n",
       "      <td>0.503890</td>\n",
       "      <td>0.908000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.234500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.521000</td>\n",
       "      <td>0.521000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.521000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.540000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-25</td>\n",
       "      <td>0.505563</td>\n",
       "      <td>0.918500</td>\n",
       "      <td>0.866700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.244400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.521000</td>\n",
       "      <td>0.521000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.521000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.532000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-26</td>\n",
       "      <td>0.503347</td>\n",
       "      <td>0.911000</td>\n",
       "      <td>0.933000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.246200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.521000</td>\n",
       "      <td>0.521000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.521000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.533000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-02-03</td>\n",
       "      <td>0.503449</td>\n",
       "      <td>0.909700</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.248000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.521000</td>\n",
       "      <td>0.521000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.521000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.629000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4983993</th>\n",
       "      <td>689009</td>\n",
       "      <td>2022-07-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.718109</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.581942</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.502263</td>\n",
       "      <td>0.500109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.749190</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-5.093013</td>\n",
       "      <td>0.500998</td>\n",
       "      <td>0.500996</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.500998</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4983994</th>\n",
       "      <td>689009</td>\n",
       "      <td>2022-07-25</td>\n",
       "      <td>0.532273</td>\n",
       "      <td>0.591823</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.585736</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.502371</td>\n",
       "      <td>0.500109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.752544</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-14.398698</td>\n",
       "      <td>0.500998</td>\n",
       "      <td>0.500996</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.500998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.540234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4983995</th>\n",
       "      <td>689009</td>\n",
       "      <td>2022-07-26</td>\n",
       "      <td>0.514619</td>\n",
       "      <td>0.669616</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.587814</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.502156</td>\n",
       "      <td>0.500109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.750539</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.956526</td>\n",
       "      <td>0.500998</td>\n",
       "      <td>0.500996</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.500998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.515320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4983996</th>\n",
       "      <td>689009</td>\n",
       "      <td>2022-07-27</td>\n",
       "      <td>0.537030</td>\n",
       "      <td>0.745145</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.591175</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.501940</td>\n",
       "      <td>0.500109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.751079</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.059825</td>\n",
       "      <td>0.500998</td>\n",
       "      <td>0.500996</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.500998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.551398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4983997</th>\n",
       "      <td>689009</td>\n",
       "      <td>2022-07-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.658777</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.594753</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.501832</td>\n",
       "      <td>0.500109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.751699</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.658573</td>\n",
       "      <td>0.500998</td>\n",
       "      <td>0.500996</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.515827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4983998 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ticker   tradeDate   alpha_0   alpha_1   alpha_2   alpha_3  alpha_4  \\\n",
       "0             1  2017-01-23  0.505398  0.926000  0.733400       NaN      NaN   \n",
       "1             1  2017-01-24  0.503890  0.908000  0.800000       NaN      NaN   \n",
       "2             1  2017-01-25  0.505563  0.918500  0.866700       NaN      NaN   \n",
       "3             1  2017-01-26  0.503347  0.911000  0.933000       NaN      NaN   \n",
       "4             1  2017-02-03  0.503449  0.909700  0.800000       NaN      NaN   \n",
       "...         ...         ...       ...       ...       ...       ...      ...   \n",
       "4983993  689009  2022-07-22       NaN  0.718109       NaN  0.581942      NaN   \n",
       "4983994  689009  2022-07-25  0.532273  0.591823  0.800000  0.585736      NaN   \n",
       "4983995  689009  2022-07-26  0.514619  0.669616  0.866667  0.587814      NaN   \n",
       "4983996  689009  2022-07-27  0.537030  0.745145  0.933333  0.591175      NaN   \n",
       "4983997  689009  2022-07-28       NaN  0.658777  0.933333  0.594753      NaN   \n",
       "\n",
       "         alpha_5   alpha_6   alpha_7  ...  alpha_56  alpha_57  alpha_58  \\\n",
       "0            NaN       NaN       NaN  ...  0.232500       NaN       NaN   \n",
       "1            NaN       NaN       NaN  ...  0.234500       NaN       NaN   \n",
       "2            NaN       NaN       NaN  ...  0.244400       NaN       NaN   \n",
       "3            NaN       NaN       NaN  ...  0.246200       NaN       NaN   \n",
       "4            NaN       NaN       NaN  ...  0.248000       NaN       NaN   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "4983993      NaN  0.502263  0.500109  ...  0.749190       NaN       NaN   \n",
       "4983994      NaN  0.502371  0.500109  ...  0.752544       NaN       NaN   \n",
       "4983995      NaN  0.502156  0.500109  ...  0.750539       NaN       NaN   \n",
       "4983996      NaN  0.501940  0.500109  ...  0.751079       NaN       NaN   \n",
       "4983997      NaN  0.501832  0.500109  ...  0.751699       NaN       NaN   \n",
       "\n",
       "          alpha_59  alpha_60  alpha_61  alpha_62  alpha_63  alpha_64  alpha_65  \n",
       "0              NaN  0.521000  0.521000       NaN  0.521000       NaN  0.516000  \n",
       "1              NaN  0.521000  0.521000       NaN  0.521000       NaN  0.540000  \n",
       "2              NaN  0.521000  0.521000       NaN  0.521000       NaN  0.532000  \n",
       "3              NaN  0.521000  0.521000       NaN  0.521000       NaN  0.533000  \n",
       "4              NaN  0.521000  0.521000       NaN  0.521000       NaN  0.629000  \n",
       "...            ...       ...       ...       ...       ...       ...       ...  \n",
       "4983993  -5.093013  0.500998  0.500996  0.933333  0.500998      15.0       NaN  \n",
       "4983994 -14.398698  0.500998  0.500996  0.833333  0.500998       NaN  0.540234  \n",
       "4983995   1.956526  0.500998  0.500996  0.833333  0.500998       NaN  0.515320  \n",
       "4983996   7.059825  0.500998  0.500996  0.933333  0.500998       NaN  0.551398  \n",
       "4983997  12.658573  0.500998  0.500996  1.000000  0.500998       NaN  0.515827  \n",
       "\n",
       "[4983998 rows x 68 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_data.to_csv('pct1_cal/每日预测/alpha_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = 'raw_data/alphas_066'\n",
    "filenames = glob.glob(path1 + '/*.csv')\n",
    "result = pd.DataFrame()\n",
    "for file in filenames[:5]:\n",
    "    i = 1\n",
    "    dic_name = file[9:19]\n",
    "    print(dic_name)\n",
    "    name = dic_name[7:] + '_' +file[20:-4]\n",
    "    print(name)\n",
    "    alpha = pd.read_csv(file)\n",
    "    alpha = alpha.loc[alpha['date'] >= '2017-01-03']\n",
    "    if dic_name == 'alphas_036':\n",
    "        alpha = alpha.rename(columns = lambda x: x[2:] if (x != 'date') else 'tradeDate')\n",
    "    else:\n",
    "        alpha = alpha.rename(columns={\"date\": \"tradeDate\"})\n",
    "    alpha = alpha.set_index(['tradeDate']).stack().reset_index().rename(columns={'level_1': 'ticker', 0: name})\n",
    "    alpha['ticker'] = alpha['ticker'].astype(int)\n",
    "    alpha = alpha.set_index(['ticker', 'tradeDate'])\n",
    "    alpha = alpha.sort_index(ascending=True)\n",
    "    if result.size == 0:\n",
    "        print('result is empty')\n",
    "        result = alpha.copy()\n",
    "    else:\n",
    "        result = pd.concat([result, alpha], axis=1)\n",
    "    print('----- Finished FILE {}------'.format(file))\n",
    "print(result)\n",
    "#result.to_csv('alphas_066.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vwap_pct1_full\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tradeDate</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>900938</th>\n",
       "      <th>900940</th>\n",
       "      <th>900941</th>\n",
       "      <th>900942</th>\n",
       "      <th>900943</th>\n",
       "      <th>900945</th>\n",
       "      <th>900946</th>\n",
       "      <th>900947</th>\n",
       "      <th>900952</th>\n",
       "      <th>900955</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>0.014194</td>\n",
       "      <td>0.011332</td>\n",
       "      <td>-0.004571</td>\n",
       "      <td>0.006056</td>\n",
       "      <td>-0.002276</td>\n",
       "      <td>0.004372</td>\n",
       "      <td>-0.001039</td>\n",
       "      <td>0.005789</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.003807</td>\n",
       "      <td>0.002755</td>\n",
       "      <td>0.005181</td>\n",
       "      <td>0.001450</td>\n",
       "      <td>0.004910</td>\n",
       "      <td>0.016313</td>\n",
       "      <td>0.001992</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.003226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>-0.003708</td>\n",
       "      <td>-0.013234</td>\n",
       "      <td>-0.012942</td>\n",
       "      <td>0.013201</td>\n",
       "      <td>0.022855</td>\n",
       "      <td>-0.024062</td>\n",
       "      <td>0.007963</td>\n",
       "      <td>-0.004350</td>\n",
       "      <td>-0.013940</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003110</td>\n",
       "      <td>0.001274</td>\n",
       "      <td>-0.006868</td>\n",
       "      <td>0.001473</td>\n",
       "      <td>-0.005793</td>\n",
       "      <td>-0.003257</td>\n",
       "      <td>-0.028892</td>\n",
       "      <td>-0.001988</td>\n",
       "      <td>-0.003774</td>\n",
       "      <td>-0.011327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>-0.003956</td>\n",
       "      <td>-0.028638</td>\n",
       "      <td>-0.002549</td>\n",
       "      <td>-0.007282</td>\n",
       "      <td>-0.019864</td>\n",
       "      <td>-0.002528</td>\n",
       "      <td>0.002184</td>\n",
       "      <td>0.004280</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001560</td>\n",
       "      <td>-0.001272</td>\n",
       "      <td>0.001383</td>\n",
       "      <td>-0.000735</td>\n",
       "      <td>-0.008740</td>\n",
       "      <td>-0.001634</td>\n",
       "      <td>0.028099</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003788</td>\n",
       "      <td>-0.003273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>-0.002664</td>\n",
       "      <td>0.011059</td>\n",
       "      <td>-0.001278</td>\n",
       "      <td>-0.014771</td>\n",
       "      <td>-0.013392</td>\n",
       "      <td>0.001690</td>\n",
       "      <td>0.008529</td>\n",
       "      <td>-0.000904</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001563</td>\n",
       "      <td>-0.006369</td>\n",
       "      <td>0.001381</td>\n",
       "      <td>-0.000736</td>\n",
       "      <td>0.012491</td>\n",
       "      <td>0.014730</td>\n",
       "      <td>-0.001608</td>\n",
       "      <td>0.001992</td>\n",
       "      <td>-0.001887</td>\n",
       "      <td>-0.003284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-09</td>\n",
       "      <td>-0.000328</td>\n",
       "      <td>-0.005390</td>\n",
       "      <td>-0.015695</td>\n",
       "      <td>-0.014501</td>\n",
       "      <td>0.003774</td>\n",
       "      <td>0.004833</td>\n",
       "      <td>-0.013388</td>\n",
       "      <td>-0.019921</td>\n",
       "      <td>-0.024560</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059468</td>\n",
       "      <td>-0.005128</td>\n",
       "      <td>-0.005517</td>\n",
       "      <td>-0.002209</td>\n",
       "      <td>-0.010160</td>\n",
       "      <td>-0.008065</td>\n",
       "      <td>-0.016103</td>\n",
       "      <td>-0.003976</td>\n",
       "      <td>0.003781</td>\n",
       "      <td>-0.004942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1287</th>\n",
       "      <td>2022-04-21</td>\n",
       "      <td>-0.047243</td>\n",
       "      <td>-0.024562</td>\n",
       "      <td>-0.075233</td>\n",
       "      <td>-0.018639</td>\n",
       "      <td>-0.056290</td>\n",
       "      <td>-0.018583</td>\n",
       "      <td>-0.030446</td>\n",
       "      <td>-0.072077</td>\n",
       "      <td>-0.059444</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012448</td>\n",
       "      <td>-0.003175</td>\n",
       "      <td>-0.028640</td>\n",
       "      <td>-0.011034</td>\n",
       "      <td>-0.028825</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>-0.053812</td>\n",
       "      <td>-0.016194</td>\n",
       "      <td>-0.011811</td>\n",
       "      <td>0.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1288</th>\n",
       "      <td>2022-04-22</td>\n",
       "      <td>-0.029172</td>\n",
       "      <td>-0.010072</td>\n",
       "      <td>-0.063486</td>\n",
       "      <td>-0.056095</td>\n",
       "      <td>-0.021734</td>\n",
       "      <td>-0.053402</td>\n",
       "      <td>-0.035825</td>\n",
       "      <td>-0.053224</td>\n",
       "      <td>-0.068637</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.040984</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.014742</td>\n",
       "      <td>-0.001395</td>\n",
       "      <td>-0.015982</td>\n",
       "      <td>0.004902</td>\n",
       "      <td>-0.014218</td>\n",
       "      <td>-0.004115</td>\n",
       "      <td>0.003984</td>\n",
       "      <td>0.009259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>2022-04-25</td>\n",
       "      <td>0.045377</td>\n",
       "      <td>-0.042534</td>\n",
       "      <td>-0.032217</td>\n",
       "      <td>-0.054750</td>\n",
       "      <td>-0.024438</td>\n",
       "      <td>-0.009689</td>\n",
       "      <td>-0.009174</td>\n",
       "      <td>0.016577</td>\n",
       "      <td>-0.008391</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.003185</td>\n",
       "      <td>0.004988</td>\n",
       "      <td>-0.002793</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.004878</td>\n",
       "      <td>0.024038</td>\n",
       "      <td>0.008264</td>\n",
       "      <td>-0.007937</td>\n",
       "      <td>-0.073394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290</th>\n",
       "      <td>2022-04-26</td>\n",
       "      <td>0.015053</td>\n",
       "      <td>0.014132</td>\n",
       "      <td>-0.060514</td>\n",
       "      <td>-0.049505</td>\n",
       "      <td>0.032389</td>\n",
       "      <td>0.049235</td>\n",
       "      <td>0.007407</td>\n",
       "      <td>0.030722</td>\n",
       "      <td>0.002208</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012780</td>\n",
       "      <td>0.007444</td>\n",
       "      <td>0.005602</td>\n",
       "      <td>0.013921</td>\n",
       "      <td>0.024510</td>\n",
       "      <td>0.009390</td>\n",
       "      <td>-0.004098</td>\n",
       "      <td>-0.008000</td>\n",
       "      <td>0.019802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1291</th>\n",
       "      <td>2022-04-27</td>\n",
       "      <td>-0.027167</td>\n",
       "      <td>0.032624</td>\n",
       "      <td>-0.067256</td>\n",
       "      <td>-0.035937</td>\n",
       "      <td>0.035539</td>\n",
       "      <td>0.018950</td>\n",
       "      <td>0.012408</td>\n",
       "      <td>0.016737</td>\n",
       "      <td>0.037445</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017094</td>\n",
       "      <td>0.009464</td>\n",
       "      <td>0.009852</td>\n",
       "      <td>0.005571</td>\n",
       "      <td>0.011442</td>\n",
       "      <td>-0.014354</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.012346</td>\n",
       "      <td>0.016129</td>\n",
       "      <td>-0.048544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1292 rows × 4859 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       tradeDate         1         2         4         5         6         7  \\\n",
       "0     2017-01-03  0.001201  0.014194  0.011332 -0.004571  0.006056 -0.002276   \n",
       "1     2017-01-04 -0.003708 -0.013234 -0.012942  0.013201  0.022855 -0.024062   \n",
       "2     2017-01-05  0.000438 -0.003956 -0.028638 -0.002549 -0.007282 -0.019864   \n",
       "3     2017-01-06  0.001204 -0.002664  0.011059 -0.001278 -0.014771 -0.013392   \n",
       "4     2017-01-09 -0.000328 -0.005390 -0.015695 -0.014501  0.003774  0.004833   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "1287  2022-04-21 -0.047243 -0.024562 -0.075233 -0.018639 -0.056290 -0.018583   \n",
       "1288  2022-04-22 -0.029172 -0.010072 -0.063486 -0.056095 -0.021734 -0.053402   \n",
       "1289  2022-04-25  0.045377 -0.042534 -0.032217 -0.054750 -0.024438 -0.009689   \n",
       "1290  2022-04-26  0.015053  0.014132 -0.060514 -0.049505  0.032389  0.049235   \n",
       "1291  2022-04-27 -0.027167  0.032624 -0.067256 -0.035937  0.035539  0.018950   \n",
       "\n",
       "             8         9        10  ...    900938    900940    900941  \\\n",
       "0     0.004372 -0.001039  0.005789  ...  0.000000 -0.003807  0.002755   \n",
       "1     0.007963 -0.004350 -0.013940  ... -0.003110  0.001274 -0.006868   \n",
       "2    -0.002528  0.002184  0.004280  ... -0.001560 -0.001272  0.001383   \n",
       "3     0.001690  0.008529 -0.000904  ... -0.001563 -0.006369  0.001381   \n",
       "4    -0.013388 -0.019921 -0.024560  ... -0.059468 -0.005128 -0.005517   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1287 -0.030446 -0.072077 -0.059444  ...  0.012448 -0.003175 -0.028640   \n",
       "1288 -0.035825 -0.053224 -0.068637  ... -0.040984  0.000000 -0.014742   \n",
       "1289 -0.009174  0.016577 -0.008391  ...  0.000000 -0.003185  0.004988   \n",
       "1290  0.007407  0.030722  0.002208  ...  0.000000  0.012780  0.007444   \n",
       "1291  0.012408  0.016737  0.037445  ...  0.017094  0.009464  0.009852   \n",
       "\n",
       "        900942    900943    900945    900946    900947    900952    900955  \n",
       "0     0.005181  0.001450  0.004910  0.016313  0.001992  0.000000 -0.003226  \n",
       "1     0.001473 -0.005793 -0.003257 -0.028892 -0.001988 -0.003774 -0.011327  \n",
       "2    -0.000735 -0.008740 -0.001634  0.028099  0.000000  0.003788 -0.003273  \n",
       "3    -0.000736  0.012491  0.014730 -0.001608  0.001992 -0.001887 -0.003284  \n",
       "4    -0.002209 -0.010160 -0.008065 -0.016103 -0.003976  0.003781 -0.004942  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1287 -0.011034 -0.028825  0.040816 -0.053812 -0.016194 -0.011811  0.058824  \n",
       "1288 -0.001395 -0.015982  0.004902 -0.014218 -0.004115  0.003984  0.009259  \n",
       "1289 -0.002793  0.000000 -0.004878  0.024038  0.008264 -0.007937 -0.073394  \n",
       "1290  0.005602  0.013921  0.024510  0.009390 -0.004098 -0.008000  0.019802  \n",
       "1291  0.005571  0.011442 -0.014354  0.023256  0.012346  0.016129 -0.048544  \n",
       "\n",
       "[1292 rows x 4859 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = 'label_vwap_pct1_full.csv'\n",
    "name = file[6:-4]\n",
    "print(name)\n",
    "label = name + '_rank'\n",
    "alpha = pd.read_csv('raw_data/' + file)\n",
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Finished FILE label_vwap_pct1_full.csv------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tradeDate</th>\n",
       "      <th>ticker</th>\n",
       "      <th>vwap_pct1_full</th>\n",
       "      <th>vwap_pct1_full_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>0.412047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.003708</td>\n",
       "      <td>0.558080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.619885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001204</td>\n",
       "      <td>0.506232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-09</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.000328</td>\n",
       "      <td>0.751037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5014493</th>\n",
       "      <td>2022-04-21</td>\n",
       "      <td>900955</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.989548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5014494</th>\n",
       "      <td>2022-04-22</td>\n",
       "      <td>900955</td>\n",
       "      <td>0.009259</td>\n",
       "      <td>0.952351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5014495</th>\n",
       "      <td>2022-04-25</td>\n",
       "      <td>900955</td>\n",
       "      <td>-0.073394</td>\n",
       "      <td>0.059131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5014496</th>\n",
       "      <td>2022-04-26</td>\n",
       "      <td>900955</td>\n",
       "      <td>0.019802</td>\n",
       "      <td>0.603679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5014497</th>\n",
       "      <td>2022-04-27</td>\n",
       "      <td>900955</td>\n",
       "      <td>-0.048544</td>\n",
       "      <td>0.019223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5014498 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          tradeDate  ticker  vwap_pct1_full  vwap_pct1_full_rank\n",
       "0        2017-01-03       1        0.001201             0.412047\n",
       "1        2017-01-04       1       -0.003708             0.558080\n",
       "2        2017-01-05       1        0.000438             0.619885\n",
       "3        2017-01-06       1        0.001204             0.506232\n",
       "4        2017-01-09       1       -0.000328             0.751037\n",
       "...             ...     ...             ...                  ...\n",
       "5014493  2022-04-21  900955        0.058824             0.989548\n",
       "5014494  2022-04-22  900955        0.009259             0.952351\n",
       "5014495  2022-04-25  900955       -0.073394             0.059131\n",
       "5014496  2022-04-26  900955        0.019802             0.603679\n",
       "5014497  2022-04-27  900955       -0.048544             0.019223\n",
       "\n",
       "[5014498 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = alpha.loc[alpha['tradeDate'] >= '2017-01-03']\n",
    "#alpha = alpha.rename(columns = lambda x: x[:-5] if (x != 'date') else 'tradeDate')\n",
    "alpha = alpha.set_index(['tradeDate']).stack().reset_index().rename(columns={'level_1': 'ticker', 0: name})\n",
    "alpha['ticker'] = alpha['ticker'].astype(int)\n",
    "alpha = alpha.sort_values(by=['ticker', 'tradeDate']).reset_index(drop=True)\n",
    "alpha[label] = alpha.groupby('tradeDate')[name].rank(pct = True)\n",
    "alpha.to_csv('labels/{}.csv'.format(name), index=False)\n",
    "print('----- Finished FILE {}------'.format(file))\n",
    "alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OutData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target(ticker_name):\n",
    "    # get close price and market value\n",
    "    outData = DataAPI.MktEqudGet(ticker=ticker_name, beginDate='2017-07-25', endDate='2022-04-05', pandas=\"1\")\n",
    "    outData = outData[['ticker', 'tradeDate', 'closePrice', 'marketValue']]\n",
    "    # get industry\n",
    "    industry_data = DataAPI.EquIndustryGet(ticker=ticker_name, pandas=\"1\")\n",
    "    industry_name = industry_data.at[0, 'industryName1']\n",
    "    # get listDate\n",
    "    list_date = DataAPI.EquGet(ticker=ticker_name ,pandas=\"1\")\n",
    "    list_date = list_date.at[0, 'listDate']\n",
    "    # combine data\n",
    "    outData['industry'] = industry_name\n",
    "    outData['listData'] = list_date\n",
    "    outData = outData.sort_values(by=['tradeDate']).reset_index(drop=True)\n",
    "    return outData[['ticker', 'tradeDate', 'marketValue', 'industry', 'listData']]\n",
    "\n",
    "print('load data')\n",
    "data = pd.read_csv('pct1_cal/1alter_alphas_066.csv', usecols=['ticker'])\n",
    "print(data)\n",
    "strData = ticekrToStr(data)\n",
    "tickers = strData.ticker.unique()\n",
    "tickers = tickers.tolist()\n",
    "\n",
    "df_merge = get_target(tickers)\n",
    "print('sort values')\n",
    "df_merge = df_merge.sort_values(by=['ticker', 'tradeDate']).reset_index(drop=True)\n",
    "print(df_merge)\n",
    "df_merge.to_csv('pct1_cal/3uqer_data.csv', index = False)\n",
    "\n",
    "df_merge.industry = df_merge.industry.fillna('其他')\n",
    "industry_to_number = {}\n",
    "for i, v in enumerate(df_merge.industry.sort_values().unique()):\n",
    "    industry_to_number[v] = i+1\n",
    "print(industry_to_number)\n",
    "df_merge.industry = df_merge.industry.map(industry_to_number)\n",
    "df_idst = pd.get_dummies(df_merge.industry, prefix='idst')\n",
    "df = df_merge.merge(df_idst, left_index=True, right_index=True)\n",
    "df['log_marketValue'] = df.marketValue.apply(np.log)\n",
    "df.to_csv('pct1_cal/4uqer_idst_log.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('========LOADING AND COMBINING ALTER DATA========')\n",
    "alpha = pd.read_csv('pct1_cal/alphas_066.csv')\n",
    "print(alpha.shape)\n",
    "print('========COMPLETE LOADING AND COMBINING ALTER DATA========')\n",
    "\n",
    "print('========LOADING ALTER DATA========')\n",
    "alter = pd.read_csv('raw_data/alternative_factors.csv')\n",
    "alter = alter.iloc[:, 1:]\n",
    "print(alter.shape)\n",
    "print('========COMPLETE LOADING ALTER DATA========')\n",
    "\n",
    "print('========COMBINING ALTER ALPHA DATA========')\n",
    "alter = alter.merge(alpha, on=['ticker', 'tradeDate'], how='left')\n",
    "del alpha\n",
    "print(alter.shape)\n",
    "print('========COMPLETE COMBINING ALTER ALPHA DATA========')\n",
    "\n",
    "print('========REALLOCATE ALTER ALPHA DATA========')\n",
    "alter = alter.dropna(thresh = 87)\n",
    "alter = reduce_mem_usage(alter)\n",
    "print(alter)\n",
    "f_x_066 = alter.columns.values.tolist()[2:]\n",
    "print(f_x_066)\n",
    "pickle.dump(f_x_066, open(\"pct1_cal/f_x_066\", \"wb\"))\n",
    "print('store alphas 222')\n",
    "alter.to_csv('pct1_cal/1alter_alphas_066.csv', index = False)\n",
    "print('========COMPLETE STORING ALTER ALPHAS 066========')\n",
    "\n",
    "#alter = pd.read_csv('pct1_cal/1alter_alphas_066.csv')\n",
    "\n",
    "print('========LOADING UQER DATA========')\n",
    "uqer_data = pd.read_csv('pct1_cal/4uqer_idst_log.csv')\n",
    "print(uqer_data.shape)\n",
    "print('========COMPLETE LOADING UQER DATA========')\n",
    "\n",
    "print('========COMBINE ALTER ALPHA UQER DATA========')\n",
    "alter = alter.merge(uqer_data, on=['ticker', 'tradeDate'], how='left')\n",
    "alter = alter[~alter.log_marketValue.isnull()]\n",
    "print(alter.shape)\n",
    "del uqer_data\n",
    "alter = reduce_mem_usage(alter)\n",
    "print('========COMPLETE COMBINE ALTER ALPHA UQER DATA========')\n",
    "\n",
    "print('get column lists')\n",
    "f_index = ['ticker', 'tradeDate']\n",
    "f_industry = pickle.load(open(\"pct1_cal/f_industry\", \"rb\"))\n",
    "f_x = pickle.load(open(\"pct1_cal/f_x_066\", \"rb\"))\n",
    "label_list = ['askbid_pct1_rank', 'openclose_pct1_rank']\n",
    "\n",
    "print('========COMBINING LABEL DATA========')\n",
    "path2 = 'labels'\n",
    "filenames = glob.glob(path2 + '/*pct1.csv')\n",
    "for file in filenames:\n",
    "    print(file)\n",
    "    label = pd.read_csv(file)\n",
    "    label_name = label.columns.values.tolist()[-1]\n",
    "    label = label[['ticker', 'tradeDate', label_name]]\n",
    "    alter = alter.merge(label, on=['ticker', 'tradeDate'], how='left')\n",
    "    del label\n",
    "alter = reduce_mem_usage(alter)\n",
    "print(alter.shape)\n",
    "print('========COMPLETE COMBINING LABEL DATA========')\n",
    "\n",
    "print('store raw data')\n",
    "alter.to_csv('pct1_cal/alter_idst_alphas_066_labels_raw.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DealWithData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('pct1_cal/alter_idst_alphas_066_labels_raw2.csv')\n",
    "print(df)\n",
    "\n",
    "print('get column lists')\n",
    "f_index = ['ticker', 'tradeDate']\n",
    "f_industry = pickle.load(open(\"pct1_cal/f_industry\", \"rb\"))\n",
    "f_x = pickle.load(open(\"pct1_cal/f_x_066\", \"rb\"))\n",
    "label_list = ['openclose_pct1'] #['PCT5_rank', 'PCT2_rank', 'openclose_pct1_rank', 'askbid_pct1_rank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'f_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/liufengyuan/liufengyuan/research集合.ipynb Cell 16\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B101.6.96.171/home/liufengyuan/liufengyuan/research%E9%9B%86%E5%90%88.ipynb#ch0000015vscode-remote?line=21'>22</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m df_columnList\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B101.6.96.171/home/liufengyuan/liufengyuan/research%E9%9B%86%E5%90%88.ipynb#ch0000015vscode-remote?line=23'>24</a>\u001b[0m \u001b[39m## fill empty values\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B101.6.96.171/home/liufengyuan/liufengyuan/research%E9%9B%86%E5%90%88.ipynb#ch0000015vscode-remote?line=24'>25</a>\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mFillEmpty\u001b[39;00m(BaseEstimator, TransformerMixin):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B101.6.96.171/home/liufengyuan/liufengyuan/research%E9%9B%86%E5%90%88.ipynb#ch0000015vscode-remote?line=25'>26</a>\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B101.6.96.171/home/liufengyuan/liufengyuan/research%E9%9B%86%E5%90%88.ipynb#ch0000015vscode-remote?line=26'>27</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdf_mean_industry \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32m/home/liufengyuan/liufengyuan/research集合.ipynb Cell 16\u001b[0m in \u001b[0;36mFillEmpty\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B101.6.96.171/home/liufengyuan/liufengyuan/research%E9%9B%86%E5%90%88.ipynb#ch0000015vscode-remote?line=25'>26</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B101.6.96.171/home/liufengyuan/liufengyuan/research%E9%9B%86%E5%90%88.ipynb#ch0000015vscode-remote?line=26'>27</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdf_mean_industry \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B101.6.96.171/home/liufengyuan/liufengyuan/research%E9%9B%86%E5%90%88.ipynb#ch0000015vscode-remote?line=28'>29</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, df_name, f_x \u001b[39m=\u001b[39m f_x, group_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mindustry\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B101.6.96.171/home/liufengyuan/liufengyuan/research%E9%9B%86%E5%90%88.ipynb#ch0000015vscode-remote?line=29'>30</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdf_mean_industry \u001b[39m=\u001b[39m df_name\u001b[39m.\u001b[39mgroupby(group_name)\u001b[39m.\u001b[39mmean()[f_x]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B101.6.96.171/home/liufengyuan/liufengyuan/research%E9%9B%86%E5%90%88.ipynb#ch0000015vscode-remote?line=30'>31</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdf_mean_industry \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdf_mean_industry\u001b[39m.\u001b[39mfillna(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdf_mean_industry\u001b[39m.\u001b[39mmean())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'f_x' is not defined"
     ]
    }
   ],
   "source": [
    "# %% a list of classes\n",
    "## exclude extreme values\n",
    "class ExcludeExtreme(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.df_median = None\n",
    "        self.df_standard = None\n",
    "\n",
    "    def fit(self, df_columnList):\n",
    "        self.df_median = df_columnList.median()\n",
    "        self.df_standard = df_columnList.apply(lambda x: x - self.df_median[x.name]).abs().median()\n",
    "        return self\n",
    "\n",
    "    def scaller(self, x):\n",
    "        self.di_max = self.df_median[x.name] + 5 * self.df_standard[x.name]\n",
    "        self.di_min = self.df_median[x.name] - 5 * self.df_standard[x.name]\n",
    "        x = x.apply(lambda v: self.di_min if v < self.di_min else v)\n",
    "        x = x.apply(lambda v: self.di_max if v > self.di_max else v)\n",
    "        return x\n",
    "\n",
    "    def transform(self, df_columnList):\n",
    "        df_columnList = df_columnList.apply(self.scaller)\n",
    "        return df_columnList\n",
    "\n",
    "## fill empty values\n",
    "class FillEmpty(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.df_mean_industry = None\n",
    "\n",
    "    def fit(self, df_name, f_x = f_x, group_name='industry'):\n",
    "        self.df_mean_industry = df_name.groupby(group_name).mean()[f_x]\n",
    "        self.df_mean_industry = self.df_mean_industry.fillna(self.df_mean_industry.mean())\n",
    "        self.df_mean_industry.columns = [x + '_mean' for x in self.df_mean_industry.columns]\n",
    "        self.df_mean_industry = self.df_mean_industry.reset_index()\n",
    "        self.df_mean_industry = self.df_mean_industry.fillna(0)  # 可以删除\n",
    "        return self\n",
    "\n",
    "    def transform(self, df_name, f_x = f_x, group_name='industry'):\n",
    "        df_name_mean = df_name.merge(self.df_mean_industry, on=group_name, how='left')\n",
    "        df_name_mean[f_x] = df_name_mean[f_x].apply(lambda x: x.fillna(df_name_mean[x.name + '_mean']))\n",
    "        df_name = df_name_mean[df_name.columns]\n",
    "        return df_name\n",
    "\n",
    "## neutralize industry\n",
    "class Neutralization(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.models = {}\n",
    "\n",
    "    def regr_fit(self, X, y):\n",
    "        self.models[y.name] = linear_model.LinearRegression().fit(X, y)\n",
    "        return\n",
    "\n",
    "    def regr_pred(self, X, y):\n",
    "        pred = self.models[y.name].predict(X)\n",
    "        return y - pred\n",
    "\n",
    "    def fit(self, df_name, f_x = f_x, f_idst = f_industry):\n",
    "        X = df_name[['log_marketValue'] + f_idst]\n",
    "        df_name[f_x].apply(lambda y: self.regr_fit(X, y))\n",
    "        return self\n",
    "\n",
    "    def transform(self, df_name, f_x = f_x, f_idst = f_industry):\n",
    "        X = df_name[['log_marketValue'] + f_idst]\n",
    "        df_name[f_x] = df_name[f_x].apply(lambda y: self.regr_pred(X, y))\n",
    "        return df_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = df.tradeDate.sort_values().unique()\n",
    "timediff = pd.Timedelta(100,unit='d')\n",
    "\n",
    "def run_df(date):\n",
    "#for date in dates:\n",
    "    print('----- DATE {}------'.format(date))\n",
    "    df2 = df[df.tradeDate == date]\n",
    "    print('处理前无效值：', df2[label_list].isnull().any().sum())\n",
    "    df2 = df2[~df2.log_marketValue.isnull()]\n",
    "    #df2 = df2[~df2.PCT2_rank.isnull()]\n",
    "    #df2 = df2[~df2.PCT5_rank.isnull()]\n",
    "    #df2 = df2[~df2.askbid_pct1_rank.isnull()]\n",
    "    df2 = df2[~df2.openclose_pct1.isnull()]\n",
    "    print('处理后无效值：', df2[label_list].isnull().any().sum())\n",
    "\n",
    "    # 中位数去极值\n",
    "    print('exclude extreme values')\n",
    "    mevtransformer = ExcludeExtreme()\n",
    "    mevtransformer.fit(df2[f_x])\n",
    "    df2[f_x] = mevtransformer.transform(df2[f_x])\n",
    "\n",
    "    # 缺失值处理\n",
    "    print('deal with null values')\n",
    "    gvfiller = FillEmpty()\n",
    "    gvfiller = gvfiller.fit(df2)\n",
    "    df2 = gvfiller.transform(df2)\n",
    "    print('缺失值：', df2[f_x].isnull().any().sum())\n",
    "\n",
    "    # 行业中性处理\n",
    "    print('do neutralization')\n",
    "    idst_neutral = Neutralization()\n",
    "    idst_neutral = idst_neutral.fit(df2)\n",
    "    df2 = idst_neutral.transform(df2)\n",
    "\n",
    "    # 标准化处理\n",
    "    print('do standardization')\n",
    "    scaler = StandardScaler()\n",
    "    df2[f_x] = scaler.fit_transform(df2[f_x])\n",
    "\n",
    "    df2 = df2[f_index + f_x + label_list + ['listData']]\n",
    "    #df1 = df1.append(df2)\n",
    "    return df2\n",
    "    #df2.to_csv('train_test/{}_data.csv'.format(date), index = False)\n",
    "\n",
    "print('PARALLEL')\n",
    "start = time.time()\n",
    "parallel_obj = Parallel(n_jobs=48)(delayed(run_df)(date) for date in dates)\n",
    "print(f'耗时:{time.time() - start}')\n",
    "df1 = pd.concat(parallel_obj)\n",
    "print('sort values')\n",
    "df1 = df1.sort_values(by=['ticker', 'tradeDate']).reset_index(drop=True)\n",
    "print('reduce memory')\n",
    "df1 = reduce_mem_usage(df1)\n",
    "print('store data')\n",
    "df1.to_csv('pct1_cal/modified_alter_alphas_066_labels2.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========LOADING DATA========\n",
      "========COMPLETE LOADING DATA========\n"
     ]
    }
   ],
   "source": [
    "####========需要修改的全局参数========####\n",
    "print('========LOADING DATA========')\n",
    "df1 = pd.read_csv('pct1_cal/modified_alter_alphas_066_labels.csv')\n",
    "label = pd.read_csv('labels/openclose_pct1_full.csv')\n",
    "print('========COMPLETE LOADING DATA========')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.merge(label, on=['ticker', 'tradeDate'], how='left')\n",
    "df1 = df1[~df1.openclose_pct1_full_rank.isnull()]\n",
    "df1 = df1[~df1.openclose_pct1_full.isnull()]\n",
    "df1 = df1[~df1.openclose_pct1_rank.isnull()]\n",
    "df1 = df1[~df1.openclose_pct1.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_x_221 = pickle.load(open('pct1_cal/每日预测/f_x_221', 'rb'))\n",
    "f_x = ['volume', 'cachgPct', 'thecommittee', 'askVolume1',\n",
    "       'bidVolume1', 'caQrr', 'caTr', 'OCVP1',\n",
    "       'Open/vwap-1', 'Gap']\n",
    "f_x.extend(f_x_221)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = ['PCT5_rank', 'PCT2_rank', 'openclose_pct1_rank', 'openclose_pct1', \n",
    "'openclose_pct1_full', 'openclose_pct1_full_rank', \n",
    "'vwap_pct1_full', 'vwap_pct1_full_rank', 'askbid_pct1_rank', 'askbid_pct1']\n",
    "f_y_list =  label_list[2:6] # 'pct_dmean'\n",
    "#f_x = pickle.load(open(\"pct1_cal/f_x_066\", \"rb\"))\n",
    "\n",
    "#e: extra, m: filted\n",
    "data_source = 'full_Alter_066_221_extra'\n",
    "file_location = 'pct1_cal'\n",
    "file_type = 'full'\n",
    "model_list = ['LinearRegression', 'RidgeR', 'DecisionTreeR', 'XGBoostR', 'LGBMRegressor']\n",
    "model_name = model_list[4]\n",
    "target_types = ['r', 'c'] # 分类问题还是回归问题 r 回归问题 c 分类问题\n",
    "target_type = target_types[0]\n",
    "####========需要修改的全局参数========####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = df1.tradeDate.sort_values().unique()\n",
    "epoch_ts = list(dates)\n",
    "f_index = ['ticker', 'tradeDate']\n",
    "#result_name = '{}_{}_{}_{}'.format(data_source, model_name, f_y, target_type)\n",
    "#print(result_name)\n",
    "\n",
    "update = 22 # 训练长度：22天\n",
    "train_si = epoch_ts.index('2017-01-03') # included. '2017-01-03'\n",
    "train_ei = epoch_ts.index('2019-01-02') # excluded. '2018-12-28'\n",
    "test_si = epoch_ts.index('2019-01-02') # included. '2019-01-02'\n",
    "test_ei = epoch_ts.index('2019-02-01') # excluded. '2019-01-31' '2019-02-01'\n",
    "test_fi = len(epoch_ts) - 1 # excluded. '2019-01-16'\n",
    "\n",
    "# number of epochs，循环次数\n",
    "num_epoch = round((test_fi - test_ei) / update)\n",
    "epoch_range = range(0, num_epoch + 1)\n",
    "timediff = pd.Timedelta(100,unit='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_lrlist(lr_max,lr_min,num_rounds):\n",
    "    lrlist = [lr_max+(lr_min-lr_max)*(np.log(i)/np.log(num_rounds)) for i in range(1,num_rounds+1)]\n",
    "    return lrlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_max = 0.05\n",
    "lr_min = 0.02\n",
    "n_jobs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gbm params\n",
    "params =  {\n",
    "    'boosting_type' : 'gbdt',\n",
    "    'num_leaves' : 31,\n",
    "    'feature_fraction' : 0.8,\n",
    "    'bagging_fraction' : 0.8,\n",
    "    'lambda_l1':1,\n",
    "    'lambda_l2':10,\n",
    "    'max_bin' : 64,\n",
    "    'num_boost_round': 200,\n",
    "    'learning_rate' : 0.04,\n",
    "    'min_data_in_leaf':10,\n",
    "    'num_threads': n_jobs\n",
    "}\n",
    "params['objective'] = 'regression'\n",
    "params['metric'] = {'l2', 'auc'}\n",
    "lrlist = load_lrlist(lr_max,lr_min,params['num_boost_round'])\n",
    "params['lrlist'] = lrlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_t_train = epoch_ts[train_si + 34*22: train_ei + 34*22]\n",
    "epoch_t_test = epoch_ts[test_si + 34*22: test_ei + 34*22]\n",
    "df_train = df1[df1.tradeDate.apply(lambda x: x in epoch_t_train)].reset_index(drop=True)\n",
    "df_test = df1[df1.tradeDate.apply(lambda x: x in epoch_t_test)].reset_index(drop=True)\n",
    "print('预测时间：', epoch_t_test)\n",
    "print('数据大小：', df_train.shape, df_test.shape)\n",
    "# 数据筛选 删除上市100天以内的\n",
    "a = pd.to_datetime(df_train.tradeDate)\n",
    "b = pd.to_datetime(df_train.listData)\n",
    "df_train = df_train[a-b > timediff]\n",
    "a = pd.to_datetime(df_test.tradeDate)\n",
    "b = pd.to_datetime(df_test.listData)\n",
    "df_test = df_test[a-b > timediff]\n",
    "\n",
    "x_train31 = df_train[f_x].values\n",
    "x_test31 = df_test[f_x].values\n",
    "print('处理后x:', x_train31.shape, x_test31.shape)\n",
    "\n",
    "# 获得y\n",
    "y_train31 = df_train[f_y].copy()\n",
    "y_test31 = df_test[f_y].copy()\n",
    "print('处理后y:', y_train31.shape, y_test31.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        #'alpha': trial.suggest_float('alpha', 0, 0.1) # 0.0005 0.0744\n",
    "        #'splitter': trial.suggest_categorical('splitter', ['random', 'best']),\n",
    "        #'criterion': trial.suggest_categorical('criterion', ['friedman_mse']),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 300, step=50),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.1, step=0.01),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.7, 1, step=0.1),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 6),\n",
    "        'subsample_freq' : trial.suggest_int('subsample_freq', 2, 8),\n",
    "        'reg_lambda' :trial.suggest_int('reg_lambda', 0, 200, step=20),\n",
    "        'num_leaves' : trial.suggest_int('num_leaves', 10, 80, step=10),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 20, 200, step=20),\n",
    "        'max_bin': trial.suggest_int('max_bin', 20, 260, step=20)\n",
    "        #'min_samples_leaf': trial.suggest_int('min_samples_leaf', 20, 60)\n",
    "    }\n",
    "    # 'n_estimators': [20], 'max_depth': [3], 'max_features': [10], 'subsample': [1.0]},\n",
    "    # 'splitter': ['random'], 'criterion': ['friedman_mse'], 'max_depth': [6], 'min_samples_leaf': [41], 'min_impurity_decrease': [0.5]\n",
    "    cv_scores = np.empty(5)\n",
    "\n",
    "    model = lgb.LGBMRegressor(**params)\n",
    "    model.fit(x_train13, y_train13)\n",
    "    y_pred13 = model.predict(x_test13)\n",
    "    df_result = pd.DataFrame({'y' : y_test13, 'y_pred': y_pred13})\n",
    "    IC13 = df_result[['y', 'y_pred']].corr().iloc[0,1]\n",
    "    print(IC13)\n",
    "    cv_scores[0] = IC13\n",
    "\n",
    "    model = lgb.LGBMRegressor(**params)\n",
    "    model.fit(x_train14, y_train14)\n",
    "    y_pred14 = model.predict(x_test14)\n",
    "    df_result = pd.DataFrame({'y' : y_test14, 'y_pred': y_pred14})\n",
    "    IC14 = df_result[['y', 'y_pred']].corr().iloc[0,1]\n",
    "    print(IC14)\n",
    "    cv_scores[1] = IC14\n",
    "\n",
    "    model = lgb.LGBMRegressor(**params)\n",
    "    model.fit(x_train19, y_train19)\n",
    "    y_pred19 = model.predict(x_test19)\n",
    "    df_result = pd.DataFrame({'y' : y_test19, 'y_pred': y_pred19})\n",
    "    IC19 = df_result[['y', 'y_pred']].corr().iloc[0,1]\n",
    "    print(IC19)\n",
    "    cv_scores[2] = IC19\n",
    "\n",
    "    model = lgb.LGBMRegressor(**params)\n",
    "    model.fit(x_train21, y_train21)\n",
    "    y_pred21 = model.predict(x_test21)\n",
    "    df_result = pd.DataFrame({'y' : y_test21, 'y_pred': y_pred21})\n",
    "    IC21 = df_result[['y', 'y_pred']].corr().iloc[0,1]\n",
    "    print(IC21)\n",
    "    cv_scores[3] = IC21\n",
    "\n",
    "    model = lgb.LGBMRegressor(**params)\n",
    "    model.fit(x_train31, y_train31)\n",
    "    y_pred31 = model.predict(x_test31)\n",
    "    df_result = pd.DataFrame({'y' : y_test31, 'y_pred': y_pred31})\n",
    "    IC31 = df_result[['y', 'y_pred']].corr().iloc[0,1]\n",
    "    print(IC31)\n",
    "    cv_scores[4] = IC31\n",
    "\n",
    "    return np.mean(cv_scores)\n",
    "\n",
    "    \"\"\"\n",
    "    cv = TimeSeriesSplit(n_splits=5, test_size = 22)\n",
    "\n",
    "    cv_scores = np.empty(5)\n",
    "\n",
    "    # LGBM\n",
    "    for idx, (train_idx, test_idx) in enumerate(cv.split(df_train[f_x], df_train[f_y])):\n",
    "        x_cv_train, x_cv_test = df_train[f_x].iloc[train_idx], df_train[f_x].iloc[test_idx]\n",
    "        y_cv_train, y_cv_test = df_train[f_y][train_idx], df_train[f_y][test_idx]\n",
    "\n",
    "        model = lgb.LGBMRegressor(**params)\n",
    "        model.fit(x_cv_train, y_cv_train)\n",
    "        y_pred = model.predict(x_cv_test)\n",
    "\n",
    "        #df_result = df_test[f_index].copy()\n",
    "        #df_result['y'] = y_test\n",
    "        #df_result['y_pred'] = y_pred\n",
    "        # 获得结果\n",
    "        df_result = pd.DataFrame({'y' : y_cv_test, 'y_pred': y_pred})\n",
    "        #IC = df_result[['y', 'y_pred']].corr().iloc[0,1]\n",
    "        cv_scores[idx] = df_result[['y', 'y_pred']].corr().iloc[0,1]\n",
    "        print(cv_scores[idx])\n",
    "    return np.mean(cv_scores)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "trial = study.best_params()\n",
    "pickle.dump(trial, open('pct1_cal/trial', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_list = []\n",
    "for num in range(0, 66):\n",
    "    alpha_list.append('alpha_{}'.format(num))\n",
    "f_x.extend(alpha_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "jingjiayinzi = pd.read_csv('pct1_cal/集合竞价因子.csv')\n",
    "jingjiayinzi = jingjiayinzi.drop(columns='Unnamed: 0')\n",
    "df1 = df1.merge(jingjiayinzi, on=['ticker', 'tradeDate'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f_y in f_y_list:\n",
    "    result_name = '{}_{}_{}_{}'.format(data_source, model_name, f_y, target_type)\n",
    "    print(result_name)\n",
    "\n",
    "    df_result_all = pd.DataFrame()\n",
    "    total_IC = 0\n",
    "    start = time.time()\n",
    "    #epoch_range = range(0, 1)\n",
    "\n",
    "    for epoch in epoch_range:\n",
    "        #epoch = num_epoch + 1\n",
    "        print('----- EPOCH {}------'.format(epoch))\n",
    "        update_n = epoch * update\n",
    "        # get a list of train dates\n",
    "        epoch_t_train = epoch_ts[train_si + update_n : train_ei + update_n]\n",
    "        # get a list of test dates\n",
    "        epoch_t_test = epoch_ts[test_si + update_n : test_ei + update_n]\n",
    "        df_train = df1[df1.tradeDate.apply(lambda x: x in epoch_t_train)].reset_index(drop=True)\n",
    "        df_test = df1[df1.tradeDate.apply(lambda x: x in epoch_t_test)].reset_index(drop=True)\n",
    "        print('预测时间：', epoch_t_test)\n",
    "        print('数据大小：', df_train.shape, df_test.shape)\n",
    "\n",
    "        # 数据筛选 删除上市100天以内的\n",
    "        #a = pd.to_datetime(df_train.tradeDate)\n",
    "        #b = pd.to_datetime(df_train.listData)\n",
    "        #df_train = df_train[a-b > timediff]\n",
    "        #a = pd.to_datetime(df_test.tradeDate)\n",
    "        #b = pd.to_datetime(df_test.listData)\n",
    "        #df_test = df_test[a-b > timediff]\n",
    "\n",
    "        # 获得 x\n",
    "        x_train = df_train[f_x].values\n",
    "        x_test = df_test[f_x].values\n",
    "        print('处理后x:', x_train.shape, x_test.shape)\n",
    "\n",
    "        # 获得y\n",
    "        y_train = df_train[f_y].values\n",
    "        y_test = df_test[f_y].values\n",
    "        #y_train = assign_weight(y_train, weightdic)\n",
    "        #y_test= assign_weight(y_test, weightdic)\n",
    "        #y_train['weight'] = 1\n",
    "        #y_test['weight'] = 1\n",
    "        print('处理后y:', y_train.shape, y_test.shape)\n",
    "        #model = XGBRegressor(n_estimators=863, max_depth=6, learning_rate = 0.0142, subsample = 0.68)\n",
    "        #model = lgb.LGBMRegressor(max_depth=5, num_leaves=10, learning_rate=0.09, n_estimators=100)\n",
    "        #model = lgb.LGBMRegressor(max_depth=6, num_leaves=25, learning_rate=0.1, n_estimators=100)\n",
    "        # {'n_estimators': 100, 'learning_rate': 0.01, 'subsample': 0.7, 'max_depth': 5, 'subsample_freq': 5, 'reg_lambda': 0, 'num_leaves': 10, 'min_child_samples': 80, 'max_bin': 20}\n",
    "        #model = lgb.LGBMRegressor(num_leaves = 15, min_child_samples=200, max_bin = 256, n_estimators=100, \\\n",
    "        #    importance_type='gain', deterministic= True, n_jobs=-1, subsample=0.9, subsample_freq=2)\n",
    "        # 'n_estimators': 100, 'learning_rate': 0.07519120996144206, 'subsample': 0.7489953327400968, 'max_depth': 6, 'subsample_freq': 8, 'reg_lambda': 50, 'num_leaves': 60\n",
    "        #model = lgb.LGBMRegressor(num_leaves= 60, n_estimators=100, learning_rate= 0.07519, reg_lambda = 50,\n",
    "        #subsample= 0.7489953, subsample_freq=8, max_depth=6)\n",
    "        #model = lgb.LGBMRegressor(**params)\n",
    "        #model.fit(x_train, y_train, eval_set=[(x_train,y_train), \n",
    "        #(x_test,y_test)], eval_metric='l2')\n",
    "        lgb_train = lgb.Dataset(x_train, y_train)\n",
    "        model = lgb.train(params,\n",
    "                        lgb_train,\n",
    "                        num_boost_round=params['num_boost_round'],\n",
    "                        callbacks = [lgb.reset_parameter(learning_rate = params['lrlist'])]\n",
    "                        )\n",
    "        y_pred = model.predict(x_test)\n",
    "\n",
    "        # 获得结果\n",
    "        print(f'耗时:{time.time() - start}')\n",
    "        print('get result')\n",
    "        df_result = df_test[f_index].copy()\n",
    "        df_result['y'] = y_test\n",
    "        df_result['y_pred'] = y_pred\n",
    "        IC = df_result[['y', 'y_pred']].corr().iloc[0,1]\n",
    "        print(IC)\n",
    "        df_result_all = df_result_all.append(df_result)\n",
    "\n",
    "    print(f'耗时:{time.time() - start}') \n",
    "    print('sort values')\n",
    "    df_result_all = df_result_all.sort_values(by=['ticker', 'tradeDate']).reset_index(drop=True)\n",
    "    IC = df_result_all[['y', 'y_pred']].corr().iloc[0,1]\n",
    "    today = (datetime.datetime.now()).strftime(\"%Y-%m-%d:%H:%M:%S\")\n",
    "    df_result_all.to_csv('{}/{}/{}{}_train_{}.csv'.format(file_location, file_type, result_name, today, round(IC, 4)), index=False)\n",
    "    print('======== COMPLETED {} {} ========'.format(model_name, IC))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import plot_importance\n",
    "plot_importance(model, max_num_features=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_x[1], f_x[2], f_x[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "parameters = {\n",
    "     'max_depth': [4, 5, 6, 7],#range(3,8,2), \n",
    "     'num_leaves': [10, 30, 60],#range(10, 170, 20), \n",
    "     'learning_rate': [0.01, 0.05, 0.1],\n",
    "     #'min_child_samples': range(10, 210, 20),\n",
    "     #'subsample': [i/10.0 for i in range(6,10)], \n",
    "     #'subsample_freq': range(1,10,1)\n",
    "}\n",
    "gbm = lgb.LGBMRegressor( objective = 'regression',\n",
    "                         learning_rate = 0.05,\n",
    "                         num_leaves = 40,\n",
    "                         n_estimators=100,\n",
    "                         max_depth=6,\n",
    "                         metrics='rmse',\n",
    "                         #subsample= 0.9, \n",
    "                         #subsample_freq=2,\n",
    "                         #min_child_samples=150,\n",
    "                         #max_bin= 256,\n",
    "                         n_jobs=-1)\n",
    "# 有了gridsearch我们便不需要fit函数\n",
    "gsearch = GridSearchCV(gbm, param_grid=parameters, scoring='neg_mean_squared_error',\\\n",
    "     cv=TimeSeriesSplit(n_splits=20, test_size=22), verbose=1, n_jobs=-1)\n",
    "gsearch.fit(x_train, y_train)\n",
    "\n",
    "print(\"Best score: %0.3f\" % gsearch.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = gsearch.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertFile(filenames, file_location):\n",
    "    for file in filenames:\n",
    "        name = file[:-26] + file[-11:-4]\n",
    "        print(name)\n",
    "        df = pd.read_csv(file_location + file)\n",
    "        df.rename(columns = {'tradeDate': 'date', 'y_pred': 'prediction'}, inplace = True)\n",
    "        df['date'] = df.date.apply(lambda x: str(x).replace('-', ''))\n",
    "        df = df[['ticker', 'date', 'prediction']]\n",
    "\n",
    "        dates = df.date.sort_values().unique()\n",
    "        def run(date):\n",
    "            print(date)\n",
    "            temp = df[df.date == date]\n",
    "            temp = temp.sort_values(by=['prediction'], ascending= False).reset_index(drop=True)\n",
    "            #temp.to_csv('Predictions/zz500_{}/{}.csv'.format(name, date), index=False)\n",
    "            temp.to_csv('{}{}/{}.csv'.format(file_location, name, date), index=False)\n",
    "\n",
    "        print('PARALLEL')\n",
    "        start = time.time()\n",
    "        parallel_obj = Parallel(n_jobs=48)(delayed(run)(date) for date in dates)\n",
    "        print(f'耗时:{time.time() - start}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full_Alter_extra_221_LGBMRegressor_openclose_pct1_full_r2022-07-31_0.1086\n",
      "PARALLEL\n",
      "20190102\n",
      "20190103\n",
      "20190104\n",
      "20190107\n",
      "20190108\n",
      "20190109\n",
      "20190110\n",
      "20190111\n",
      "20190114\n",
      "20190115\n",
      "20190116\n",
      "20190117\n",
      "20190118\n",
      "20190121\n",
      "20190122\n",
      "20190123\n",
      "20190124\n",
      "20190125\n",
      "20190128\n",
      "20190129\n",
      "20190130\n",
      "20190131\n",
      "20190201\n",
      "20190211\n",
      "20190212\n",
      "20190213\n",
      "20190214\n",
      "20190215\n",
      "20190218\n",
      "20190219\n",
      "20190220\n",
      "20190221\n",
      "20190222\n",
      "20190225\n",
      "20190226\n",
      "20190227\n",
      "20190228\n",
      "20190301\n",
      "20190304\n",
      "20190305\n",
      "20190306\n",
      "20190307\n",
      "20190308\n",
      "20190311\n",
      "20190312\n",
      "20190313\n",
      "20190314\n",
      "20190315\n",
      "20190318\n",
      "20190319\n"
     ]
    }
   ],
   "source": [
    "filenames = ['full_Alter_extra_221_LGBMRegressor_openclose_pct1_full_r2022-07-31:11:06:20_train_0.1086.csv',\n",
    "'full_Alter_extra_221_LGBMRegressor_openclose_pct1_full_rank_r2022-07-31:11:38:20_train_0.1734.csv',\n",
    "'full_Alter_extra_221_LGBMRegressor_openclose_pct1_r2022-07-31:10:37:38_train_0.1606.csv',\n",
    "'full_Alter_extra_221_LGBMRegressor_openclose_pct1_rank_r2022-07-31:10:07:00_train_0.1752.csv']\n",
    "file_location = 'pct1_cal/full/'\n",
    "convertFile(filenames, file_location)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "0c4e795b307436e90878d87b7b6ea0f9ae1f8d88c9c1ffc8ae37ae0851c943d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
