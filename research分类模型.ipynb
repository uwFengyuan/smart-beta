{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import lightgbm as lgb\n",
    "import glob\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from joblib import Parallel, delayed\n",
    "import time\n",
    "from sklearn.metrics import log_loss, accuracy_score, f1_score, plot_roc_curve\n",
    "import datetime\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import optuna\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import log_loss, accuracy_score, f1_score, plot_roc_curve\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========LOADING DATA========\n",
      "(569537, 293)\n",
      "========COMPLETE LOADING DATA========\n"
     ]
    }
   ],
   "source": [
    "print('========LOADING DATA========')\n",
    "df_500 = pd.read_csv('pct1_cal/modified_alter_alphas_066_labels_500.csv')\n",
    "print(df_500.shape)\n",
    "print('========COMPLETE LOADING DATA========')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_samples = [0.5, 0.4, 0.3, 0.2, 0.1] # 训练集样本量 0.5表示前后50%都选 即全部数据都选；0.3表示取涨幅前后30% 共60% 的样本量 \n",
    "percent_sample = percent_samples[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 采样比例\n",
    "if percent_sample==0.5:\n",
    "    qcut_q = [0, 0.5, 1]\n",
    "    qcut_labels = [0, 1]\n",
    "else:\n",
    "    qcut_q = [0, percent_sample, 1-percent_sample, 1]\n",
    "    qcut_labels = [0, -1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Bin labels must be one fewer than the number of bin edges",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-5de1792b44d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_500\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'openclose_pct1_label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_500\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tradeDate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopenclose_pct1_rank\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqcut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mqcut_q\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mqcut_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduplicates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'drop'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/groupby/generic.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    224\u001b[0m     )\n\u001b[1;32m    225\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     @doc(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0moption_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mode.chained_assignment\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_apply_general\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selected_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                 \u001b[0;31m# gh-20949\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m_python_apply_general\u001b[0;34m(self, f, data)\u001b[0m\n\u001b[1;32m    890\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mapplying\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \"\"\"\n\u001b[0;32m--> 892\u001b[0;31m         \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m         return self._wrap_applied_output(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, data, axis)\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0;31m# group might be modified\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0mgroup_axes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_indexed_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_axes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mmutated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-5de1792b44d1>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_500\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'openclose_pct1_label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_500\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tradeDate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopenclose_pct1_rank\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqcut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mqcut_q\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mqcut_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduplicates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'drop'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/reshape/tile.py\u001b[0m in \u001b[0;36mqcut\u001b[0;34m(x, q, labels, retbins, precision, duplicates)\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0minclude_lowest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0mduplicates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mduplicates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m     )\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/reshape/tile.py\u001b[0m in \u001b[0;36m_bins_to_cuts\u001b[0;34m(x, bins, right, labels, precision, include_lowest, dtype, duplicates, ordered)\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m                 raise ValueError(\n\u001b[0;32m--> 435\u001b[0;31m                     \u001b[0;34m\"Bin labels must be one fewer than the number of bin edges\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m                 )\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_categorical_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Bin labels must be one fewer than the number of bin edges"
     ]
    }
   ],
   "source": [
    "df_500['openclose_pct1_label'] = df_500.groupby('tradeDate').openclose_pct1_rank.apply(lambda x: pd.qcut(x, q=qcut_q, labels=qcut_labels, duplicates='drop'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_500 = df_500[(df_500['openclose_pct1_label']==0) | (df_500['openclose_pct1_label']==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>tradeDate</th>\n",
       "      <th>minute_new_FACTORS_CDPDP</th>\n",
       "      <th>minute_new_FACTORS_CDPP</th>\n",
       "      <th>minute_new_FACTORS_Down_beta</th>\n",
       "      <th>minute_new_FACTORS_ILLIQ</th>\n",
       "      <th>minute_new_FACTORS_IMI</th>\n",
       "      <th>minute_new_FACTORS_PVC</th>\n",
       "      <th>minute_new_FACTORS_TMA_turn</th>\n",
       "      <th>minute_new_FACTORS_TSMOM</th>\n",
       "      <th>...</th>\n",
       "      <th>alpha_27</th>\n",
       "      <th>alpha_11</th>\n",
       "      <th>alpha_42</th>\n",
       "      <th>alpha_12</th>\n",
       "      <th>alpha_1</th>\n",
       "      <th>alpha_23</th>\n",
       "      <th>alpha_5</th>\n",
       "      <th>alpha_9</th>\n",
       "      <th>alpha_31</th>\n",
       "      <th>openclose_pct1_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>-1.47100</td>\n",
       "      <td>2.125000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.694300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.256000</td>\n",
       "      <td>0.6616</td>\n",
       "      <td>-0.2969</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.79600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>-1.40400</td>\n",
       "      <td>1.884000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.682000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.074000</td>\n",
       "      <td>0.9795</td>\n",
       "      <td>-0.8984</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.18620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>-0.00638</td>\n",
       "      <td>1.806000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.708000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.023000</td>\n",
       "      <td>1.0360</td>\n",
       "      <td>-1.1230</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.63600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>-0.01643</td>\n",
       "      <td>1.675000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.868000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.468000</td>\n",
       "      <td>1.0280</td>\n",
       "      <td>-0.8257</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.68500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>2017-01-09</td>\n",
       "      <td>-0.01038</td>\n",
       "      <td>1.354000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.914600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.424000</td>\n",
       "      <td>1.0520</td>\n",
       "      <td>-0.8170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.84900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569532</th>\n",
       "      <td>689009</td>\n",
       "      <td>2022-03-28</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.043100</td>\n",
       "      <td>0.0841</td>\n",
       "      <td>-0.005463</td>\n",
       "      <td>-0.592000</td>\n",
       "      <td>-0.072750</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.7573</td>\n",
       "      <td>...</td>\n",
       "      <td>0.24490</td>\n",
       "      <td>0.5015</td>\n",
       "      <td>-0.04517</td>\n",
       "      <td>0.00635</td>\n",
       "      <td>1.895</td>\n",
       "      <td>2.7420</td>\n",
       "      <td>-0.2764</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1385</td>\n",
       "      <td>0.90870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569533</th>\n",
       "      <td>689009</td>\n",
       "      <td>2022-03-29</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.131500</td>\n",
       "      <td>0.0883</td>\n",
       "      <td>-0.005413</td>\n",
       "      <td>-0.003313</td>\n",
       "      <td>0.048680</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3320</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.04490</td>\n",
       "      <td>0.5640</td>\n",
       "      <td>-0.04993</td>\n",
       "      <td>1.19700</td>\n",
       "      <td>1.558</td>\n",
       "      <td>-2.0760</td>\n",
       "      <td>-0.4504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2303</td>\n",
       "      <td>0.02888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569534</th>\n",
       "      <td>689009</td>\n",
       "      <td>2022-03-30</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.015480</td>\n",
       "      <td>0.1278</td>\n",
       "      <td>-0.012070</td>\n",
       "      <td>-0.546000</td>\n",
       "      <td>0.088750</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.8220</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.04490</td>\n",
       "      <td>0.6514</td>\n",
       "      <td>-0.04703</td>\n",
       "      <td>-1.55500</td>\n",
       "      <td>-1.620</td>\n",
       "      <td>0.2030</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2053</td>\n",
       "      <td>0.34350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569535</th>\n",
       "      <td>689009</td>\n",
       "      <td>2022-03-31</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-0.019520</td>\n",
       "      <td>0.5350</td>\n",
       "      <td>-0.015750</td>\n",
       "      <td>-0.527000</td>\n",
       "      <td>-0.044400</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.9720</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.04495</td>\n",
       "      <td>0.6450</td>\n",
       "      <td>-0.04620</td>\n",
       "      <td>1.47800</td>\n",
       "      <td>-1.434</td>\n",
       "      <td>2.0600</td>\n",
       "      <td>0.4358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2075</td>\n",
       "      <td>0.27600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569536</th>\n",
       "      <td>689009</td>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.008385</td>\n",
       "      <td>0.7627</td>\n",
       "      <td>-0.017760</td>\n",
       "      <td>-0.555000</td>\n",
       "      <td>-0.015144</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-0.9126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.5938</td>\n",
       "      <td>-0.03976</td>\n",
       "      <td>1.32400</td>\n",
       "      <td>-1.454</td>\n",
       "      <td>0.9756</td>\n",
       "      <td>-0.9950</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2360</td>\n",
       "      <td>0.21500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569537 rows × 293 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ticker   tradeDate  minute_new_FACTORS_CDPDP  minute_new_FACTORS_CDPP  \\\n",
       "0            9  2017-01-03                  -1.47100                 2.125000   \n",
       "1            9  2017-01-04                  -1.40400                 1.884000   \n",
       "2            9  2017-01-05                  -0.00638                 1.806000   \n",
       "3            9  2017-01-06                  -0.01643                 1.675000   \n",
       "4            9  2017-01-09                  -0.01038                 1.354000   \n",
       "...        ...         ...                       ...                      ...   \n",
       "569532  689009  2022-03-28                   0.00000                -0.043100   \n",
       "569533  689009  2022-03-29                   0.00000                 0.131500   \n",
       "569534  689009  2022-03-30                   0.00000                 0.015480   \n",
       "569535  689009  2022-03-31                   0.00000                -0.019520   \n",
       "569536  689009  2022-04-01                   0.00000                 0.008385   \n",
       "\n",
       "        minute_new_FACTORS_Down_beta  minute_new_FACTORS_ILLIQ  \\\n",
       "0                             0.0000                 -0.694300   \n",
       "1                             0.0000                 -0.682000   \n",
       "2                             0.0000                 -0.708000   \n",
       "3                             0.0000                 -0.868000   \n",
       "4                             0.0000                 -0.914600   \n",
       "...                              ...                       ...   \n",
       "569532                        0.0841                 -0.005463   \n",
       "569533                        0.0883                 -0.005413   \n",
       "569534                        0.1278                 -0.012070   \n",
       "569535                        0.5350                 -0.015750   \n",
       "569536                        0.7627                 -0.017760   \n",
       "\n",
       "        minute_new_FACTORS_IMI  minute_new_FACTORS_PVC  \\\n",
       "0                     0.000000                2.256000   \n",
       "1                     0.000000                2.074000   \n",
       "2                     0.000000                2.023000   \n",
       "3                     0.000000                1.468000   \n",
       "4                     0.000000                1.424000   \n",
       "...                        ...                     ...   \n",
       "569532               -0.592000               -0.072750   \n",
       "569533               -0.003313                0.048680   \n",
       "569534               -0.546000                0.088750   \n",
       "569535               -0.527000               -0.044400   \n",
       "569536               -0.555000               -0.015144   \n",
       "\n",
       "        minute_new_FACTORS_TMA_turn  minute_new_FACTORS_TSMOM  ...  alpha_27  \\\n",
       "0                            0.6616                   -0.2969  ...   0.00000   \n",
       "1                            0.9795                   -0.8984  ...   0.00000   \n",
       "2                            1.0360                   -1.1230  ...   0.00000   \n",
       "3                            1.0280                   -0.8257  ...   0.00000   \n",
       "4                            1.0520                   -0.8170  ...   0.00000   \n",
       "...                             ...                       ...  ...       ...   \n",
       "569532                       0.0000                    0.7573  ...   0.24490   \n",
       "569533                       0.0000                    0.3320  ...  -0.04490   \n",
       "569534                       0.0000                   -0.8220  ...  -0.04490   \n",
       "569535                       0.0000                   -0.9720  ...  -0.04495   \n",
       "569536                       0.0000                   -0.9126  ...   0.00000   \n",
       "\n",
       "        alpha_11  alpha_42  alpha_12  alpha_1  alpha_23  alpha_5  alpha_9  \\\n",
       "0         0.0000   0.00000   0.00000    0.000    0.0000   0.0000      0.0   \n",
       "1         0.0000   0.00000   0.00000    0.000    0.0000   0.0000      0.0   \n",
       "2         0.0000   0.00000   0.00000    0.000    0.0000   0.0000      0.0   \n",
       "3         0.0000   0.00000   0.00000    0.000    0.0000   0.0000      0.0   \n",
       "4         0.0000   0.00000   0.00000    0.000    0.0000   0.0000      0.0   \n",
       "...          ...       ...       ...      ...       ...      ...      ...   \n",
       "569532    0.5015  -0.04517   0.00635    1.895    2.7420  -0.2764      0.0   \n",
       "569533    0.5640  -0.04993   1.19700    1.558   -2.0760  -0.4504      0.0   \n",
       "569534    0.6514  -0.04703  -1.55500   -1.620    0.2030   0.0000      0.0   \n",
       "569535    0.6450  -0.04620   1.47800   -1.434    2.0600   0.4358      0.0   \n",
       "569536    0.5938  -0.03976   1.32400   -1.454    0.9756  -0.9950      0.0   \n",
       "\n",
       "        alpha_31  openclose_pct1_rank  \n",
       "0         0.0000              0.79600  \n",
       "1         0.0000              0.18620  \n",
       "2         0.0000              0.63600  \n",
       "3         0.0000              0.68500  \n",
       "4         0.0000              0.84900  \n",
       "...          ...                  ...  \n",
       "569532    0.1385              0.90870  \n",
       "569533    0.2303              0.02888  \n",
       "569534    0.2053              0.34350  \n",
       "569535    0.2075              0.27600  \n",
       "569536    0.2360              0.21500  \n",
       "\n",
       "[569537 rows x 293 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     34767\n",
       "1     34658\n",
       "-1        0\n",
       "Name: openclose_pct1_label, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_500.openclose_pct1_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== LEN_TRAIN openclose_pct1_label ========\n",
      "500_Alter_066_full_LGBMClassifier-openclose_pct1_label-c\n",
      "----- EPOCH 0------\n",
      "预测时间： ['2019-01-02', '2019-01-03', '2019-01-04', '2019-01-07', '2019-01-08', '2019-01-09', '2019-01-10', '2019-01-11', '2019-01-14', '2019-01-15', '2019-01-16', '2019-01-17', '2019-01-18', '2019-01-21', '2019-01-22', '2019-01-23', '2019-01-24', '2019-01-25', '2019-01-28', '2019-01-29', '2019-01-30', '2019-01-31']\n",
      "数据大小： (24008, 294) (1180, 294)\n",
      "y： (24008,) (1180,)\n",
      "get result\n",
      "----- EPOCH 1------\n",
      "预测时间： ['2019-02-01', '2019-02-11', '2019-02-12', '2019-02-13', '2019-02-14', '2019-02-15', '2019-02-18', '2019-02-19', '2019-02-20', '2019-02-21', '2019-02-22', '2019-02-25', '2019-02-26', '2019-02-27', '2019-02-28', '2019-03-01', '2019-03-04', '2019-03-05', '2019-03-06', '2019-03-07', '2019-03-08', '2019-03-11']\n",
      "数据大小： (24176, 294) (1188, 294)\n",
      "y： (24176,) (1188,)\n",
      "get result\n",
      "----- EPOCH 2------\n",
      "预测时间： ['2019-03-12', '2019-03-13', '2019-03-14', '2019-03-15', '2019-03-18', '2019-03-19', '2019-03-20', '2019-03-21', '2019-03-22', '2019-03-25', '2019-03-26', '2019-03-27', '2019-03-28', '2019-03-29', '2019-04-01', '2019-04-02', '2019-04-03', '2019-04-04', '2019-04-08', '2019-04-09', '2019-04-10', '2019-04-11']\n",
      "数据大小： (24332, 294) (1183, 294)\n",
      "y： (24332,) (1183,)\n",
      "get result\n",
      "----- EPOCH 3------\n",
      "预测时间： ['2019-04-12', '2019-04-15', '2019-04-16', '2019-04-17', '2019-04-18', '2019-04-19', '2019-04-22', '2019-04-23', '2019-04-24', '2019-04-25', '2019-04-26', '2019-04-29', '2019-04-30', '2019-05-06', '2019-05-07', '2019-05-08', '2019-05-09', '2019-05-10', '2019-05-13', '2019-05-14', '2019-05-15', '2019-05-16']\n",
      "数据大小： (24452, 294) (1187, 294)\n",
      "y： (24452,) (1187,)\n",
      "get result\n",
      "----- EPOCH 4------\n",
      "预测时间： ['2019-05-17', '2019-05-20', '2019-05-21', '2019-05-22', '2019-05-23', '2019-05-24', '2019-05-27', '2019-05-28', '2019-05-29', '2019-05-30', '2019-05-31', '2019-06-03', '2019-06-04', '2019-06-05', '2019-06-06', '2019-06-10', '2019-06-11', '2019-06-12', '2019-06-13', '2019-06-14', '2019-06-17', '2019-06-18']\n",
      "数据大小： (24586, 294) (1186, 294)\n",
      "y： (24586,) (1186,)\n",
      "get result\n",
      "----- EPOCH 5------\n",
      "预测时间： ['2019-06-19', '2019-06-20', '2019-06-21', '2019-06-24', '2019-06-25', '2019-06-26', '2019-06-27', '2019-06-28', '2019-07-01', '2019-07-02', '2019-07-03', '2019-07-04', '2019-07-05', '2019-07-08', '2019-07-09', '2019-07-10', '2019-07-11', '2019-07-12', '2019-07-15', '2019-07-16', '2019-07-17', '2019-07-18']\n",
      "数据大小： (24719, 294) (1194, 294)\n",
      "y： (24719,) (1194,)\n",
      "get result\n",
      "----- EPOCH 6------\n",
      "预测时间： ['2019-07-19', '2019-07-22', '2019-07-23', '2019-07-24', '2019-07-25', '2019-07-26', '2019-07-29', '2019-07-30', '2019-07-31', '2019-08-01', '2019-08-02', '2019-08-05', '2019-08-06', '2019-08-07', '2019-08-08', '2019-08-09', '2019-08-12', '2019-08-13', '2019-08-14', '2019-08-15', '2019-08-16', '2019-08-19']\n",
      "数据大小： (24858, 294) (1226, 294)\n",
      "y： (24858,) (1226,)\n",
      "get result\n",
      "----- EPOCH 7------\n",
      "预测时间： ['2019-08-20', '2019-08-21', '2019-08-22', '2019-08-23', '2019-08-26', '2019-08-27', '2019-08-28', '2019-08-29', '2019-08-30', '2019-09-02', '2019-09-03', '2019-09-04', '2019-09-05', '2019-09-06', '2019-09-09', '2019-09-10', '2019-09-11', '2019-09-12', '2019-09-16', '2019-09-17', '2019-09-18', '2019-09-19']\n",
      "数据大小： (25033, 294) (1231, 294)\n",
      "y： (25033,) (1231,)\n",
      "get result\n",
      "----- EPOCH 8------\n",
      "预测时间： ['2019-09-20', '2019-09-23', '2019-09-24', '2019-09-25', '2019-09-26', '2019-09-27', '2019-09-30', '2019-10-08', '2019-10-09', '2019-10-10', '2019-10-11', '2019-10-14', '2019-10-15', '2019-10-16', '2019-10-17', '2019-10-18', '2019-10-21', '2019-10-22', '2019-10-23', '2019-10-24', '2019-10-25', '2019-10-28']\n",
      "数据大小： (25209, 294) (1230, 294)\n",
      "y： (25209,) (1230,)\n",
      "get result\n",
      "----- EPOCH 9------\n",
      "预测时间： ['2019-10-29', '2019-10-30', '2019-10-31', '2019-11-01', '2019-11-04', '2019-11-05', '2019-11-06', '2019-11-07', '2019-11-08', '2019-11-11', '2019-11-12', '2019-11-13', '2019-11-14', '2019-11-15', '2019-11-18', '2019-11-19', '2019-11-20', '2019-11-21', '2019-11-22', '2019-11-25', '2019-11-26', '2019-11-27']\n",
      "数据大小： (25384, 294) (1228, 294)\n",
      "y： (25384,) (1228,)\n",
      "get result\n",
      "----- EPOCH 10------\n",
      "预测时间： ['2019-11-28', '2019-11-29', '2019-12-02', '2019-12-03', '2019-12-04', '2019-12-05', '2019-12-06', '2019-12-09', '2019-12-10', '2019-12-11', '2019-12-12', '2019-12-13', '2019-12-16', '2019-12-17', '2019-12-18', '2019-12-19', '2019-12-20', '2019-12-23', '2019-12-24', '2019-12-25', '2019-12-26', '2019-12-27']\n",
      "数据大小： (25557, 294) (1230, 294)\n",
      "y： (25557,) (1230,)\n",
      "get result\n",
      "----- EPOCH 11------\n",
      "预测时间： ['2019-12-30', '2019-12-31', '2020-01-02', '2020-01-03', '2020-01-06', '2020-01-07', '2020-01-08', '2020-01-09', '2020-01-10', '2020-01-13', '2020-01-14', '2020-01-15', '2020-01-16', '2020-01-17', '2020-01-20', '2020-01-21', '2020-01-22', '2020-01-23', '2020-02-03', '2020-02-04', '2020-02-05', '2020-02-06']\n",
      "数据大小： (25723, 294) (1240, 294)\n",
      "y： (25723,) (1240,)\n",
      "get result\n",
      "----- EPOCH 12------\n",
      "预测时间： ['2020-02-07', '2020-02-10', '2020-02-11', '2020-02-12', '2020-02-13', '2020-02-14', '2020-02-17', '2020-02-18', '2020-02-19', '2020-02-20', '2020-02-21', '2020-02-24', '2020-02-25', '2020-02-26', '2020-02-27', '2020-02-28', '2020-03-02', '2020-03-03', '2020-03-04', '2020-03-05', '2020-03-06', '2020-03-09']\n",
      "数据大小： (25866, 294) (1231, 294)\n",
      "y： (25866,) (1231,)\n",
      "get result\n",
      "----- EPOCH 13------\n",
      "预测时间： ['2020-03-10', '2020-03-11', '2020-03-12', '2020-03-13', '2020-03-16', '2020-03-17', '2020-03-18', '2020-03-19', '2020-03-20', '2020-03-23', '2020-03-24', '2020-03-25', '2020-03-26', '2020-03-27', '2020-03-30', '2020-03-31', '2020-04-01', '2020-04-02', '2020-04-03', '2020-04-07', '2020-04-08', '2020-04-09']\n",
      "数据大小： (26002, 294) (1232, 294)\n",
      "y： (26002,) (1232,)\n",
      "get result\n",
      "----- EPOCH 14------\n",
      "预测时间： ['2020-04-10', '2020-04-13', '2020-04-14', '2020-04-15', '2020-04-16', '2020-04-17', '2020-04-20', '2020-04-21', '2020-04-22', '2020-04-23', '2020-04-24', '2020-04-27', '2020-04-28', '2020-04-29', '2020-04-30', '2020-05-06', '2020-05-07', '2020-05-08', '2020-05-11', '2020-05-12', '2020-05-13', '2020-05-14']\n",
      "数据大小： (26141, 294) (1236, 294)\n",
      "y： (26141,) (1236,)\n",
      "get result\n",
      "----- EPOCH 15------\n",
      "预测时间： ['2020-05-15', '2020-05-18', '2020-05-19', '2020-05-20', '2020-05-21', '2020-05-22', '2020-05-25', '2020-05-26', '2020-05-27', '2020-05-28', '2020-05-29', '2020-06-01', '2020-06-02', '2020-06-03', '2020-06-04', '2020-06-05', '2020-06-08', '2020-06-09', '2020-06-10', '2020-06-11', '2020-06-12', '2020-06-15']\n",
      "数据大小： (26278, 294) (1249, 294)\n",
      "y： (26278,) (1249,)\n",
      "get result\n",
      "----- EPOCH 16------\n",
      "预测时间： ['2020-06-16', '2020-06-17', '2020-06-18', '2020-06-19', '2020-06-22', '2020-06-23', '2020-06-24', '2020-06-29', '2020-06-30', '2020-07-01', '2020-07-02', '2020-07-03', '2020-07-06', '2020-07-07', '2020-07-08', '2020-07-09', '2020-07-10', '2020-07-13', '2020-07-14', '2020-07-15', '2020-07-16', '2020-07-17']\n",
      "数据大小： (26425, 294) (1281, 294)\n",
      "y： (26425,) (1281,)\n",
      "get result\n",
      "----- EPOCH 17------\n",
      "预测时间： ['2020-07-20', '2020-07-21', '2020-07-22', '2020-07-23', '2020-07-24', '2020-07-27', '2020-07-28', '2020-07-29', '2020-07-30', '2020-07-31', '2020-08-03', '2020-08-04', '2020-08-05', '2020-08-06', '2020-08-07', '2020-08-10', '2020-08-11', '2020-08-12', '2020-08-13', '2020-08-14', '2020-08-17', '2020-08-18']\n",
      "数据大小： (26606, 294) (1276, 294)\n",
      "y： (26606,) (1276,)\n",
      "get result\n",
      "----- EPOCH 18------\n",
      "预测时间： ['2020-08-19', '2020-08-20', '2020-08-21', '2020-08-24', '2020-08-25', '2020-08-26', '2020-08-27', '2020-08-28', '2020-08-31', '2020-09-01', '2020-09-02', '2020-09-03', '2020-09-04', '2020-09-07', '2020-09-08', '2020-09-09', '2020-09-10', '2020-09-11', '2020-09-14', '2020-09-15', '2020-09-16', '2020-09-17']\n",
      "数据大小： (26783, 294) (1273, 294)\n",
      "y： (26783,) (1273,)\n",
      "get result\n",
      "----- EPOCH 19------\n",
      "预测时间： ['2020-09-18', '2020-09-21', '2020-09-22', '2020-09-23', '2020-09-24', '2020-09-25', '2020-09-28', '2020-09-29', '2020-09-30', '2020-10-09', '2020-10-12', '2020-10-13', '2020-10-14', '2020-10-15', '2020-10-16', '2020-10-19', '2020-10-20', '2020-10-21', '2020-10-22', '2020-10-23', '2020-10-26', '2020-10-27']\n",
      "数据大小： (26928, 294) (1275, 294)\n",
      "y： (26928,) (1275,)\n",
      "get result\n",
      "----- EPOCH 20------\n",
      "预测时间： ['2020-10-28', '2020-10-29', '2020-10-30', '2020-11-02', '2020-11-03', '2020-11-04', '2020-11-05', '2020-11-06', '2020-11-09', '2020-11-10', '2020-11-11', '2020-11-12', '2020-11-13', '2020-11-16', '2020-11-17', '2020-11-18', '2020-11-19', '2020-11-20', '2020-11-23', '2020-11-24', '2020-11-25', '2020-11-26']\n",
      "数据大小： (27061, 294) (1272, 294)\n",
      "y： (27061,) (1272,)\n",
      "get result\n",
      "----- EPOCH 21------\n",
      "预测时间： ['2020-11-27', '2020-11-30', '2020-12-01', '2020-12-02', '2020-12-03', '2020-12-04', '2020-12-07', '2020-12-08', '2020-12-09', '2020-12-10', '2020-12-11', '2020-12-14', '2020-12-15', '2020-12-16', '2020-12-17', '2020-12-18', '2020-12-21', '2020-12-22', '2020-12-23', '2020-12-24', '2020-12-25', '2020-12-28']\n",
      "数据大小： (27162, 294) (1316, 294)\n",
      "y： (27162,) (1316,)\n",
      "get result\n",
      "----- EPOCH 22------\n",
      "预测时间： ['2020-12-29', '2020-12-30', '2020-12-31', '2021-01-04', '2021-01-05', '2021-01-06', '2021-01-07', '2021-01-08', '2021-01-11', '2021-01-12', '2021-01-13', '2021-01-14', '2021-01-15', '2021-01-18', '2021-01-19', '2021-01-20', '2021-01-21', '2021-01-22', '2021-01-25', '2021-01-26', '2021-01-27', '2021-01-28']\n",
      "数据大小： (27302, 294) (1315, 294)\n",
      "y： (27302,) (1315,)\n",
      "get result\n",
      "----- EPOCH 23------\n",
      "预测时间： ['2021-01-29', '2021-02-01', '2021-02-02', '2021-02-03', '2021-02-04', '2021-02-05', '2021-02-08', '2021-02-09', '2021-02-10', '2021-02-18', '2021-02-19', '2021-02-22', '2021-02-23', '2021-02-24', '2021-02-25', '2021-02-26', '2021-03-01', '2021-03-02', '2021-03-03', '2021-03-04', '2021-03-05', '2021-03-08']\n",
      "数据大小： (27440, 294) (1317, 294)\n",
      "y： (27440,) (1317,)\n",
      "get result\n",
      "----- EPOCH 24------\n",
      "预测时间： ['2021-03-09', '2021-03-10', '2021-03-11', '2021-03-12', '2021-03-15', '2021-03-16', '2021-03-17', '2021-03-18', '2021-03-19', '2021-03-22', '2021-03-23', '2021-03-24', '2021-03-25', '2021-03-26', '2021-03-29', '2021-03-30', '2021-03-31', '2021-04-01', '2021-04-02', '2021-04-06', '2021-04-07', '2021-04-08']\n",
      "数据大小： (27570, 294) (1317, 294)\n",
      "y： (27570,) (1317,)\n",
      "get result\n",
      "----- EPOCH 25------\n",
      "预测时间： ['2021-04-09', '2021-04-12', '2021-04-13', '2021-04-14', '2021-04-15', '2021-04-16', '2021-04-19', '2021-04-20', '2021-04-21', '2021-04-22', '2021-04-23', '2021-04-26', '2021-04-27', '2021-04-28', '2021-04-29', '2021-04-30', '2021-05-06', '2021-05-07', '2021-05-10', '2021-05-11', '2021-05-12', '2021-05-13']\n",
      "数据大小： (27704, 294) (1316, 294)\n",
      "y： (27704,) (1316,)\n",
      "get result\n",
      "----- EPOCH 26------\n",
      "预测时间： ['2021-05-14', '2021-05-17', '2021-05-18', '2021-05-19', '2021-05-20', '2021-05-21', '2021-05-24', '2021-05-25', '2021-05-26', '2021-05-27', '2021-05-28', '2021-05-31', '2021-06-01', '2021-06-02', '2021-06-03', '2021-06-04', '2021-06-07', '2021-06-08', '2021-06-09', '2021-06-10', '2021-06-11', '2021-06-15']\n",
      "数据大小： (27832, 294) (1319, 294)\n",
      "y： (27832,) (1319,)\n",
      "get result\n",
      "----- EPOCH 27------\n",
      "预测时间： ['2021-06-16', '2021-06-17', '2021-06-18', '2021-06-21', '2021-06-22', '2021-06-23', '2021-06-24', '2021-06-25', '2021-06-28', '2021-06-29', '2021-06-30', '2021-07-01', '2021-07-02', '2021-07-05', '2021-07-06', '2021-07-07', '2021-07-08', '2021-07-09', '2021-07-12', '2021-07-13', '2021-07-14', '2021-07-15']\n",
      "数据大小： (27966, 294) (1319, 294)\n",
      "y： (27966,) (1319,)\n",
      "get result\n",
      "----- EPOCH 28------\n",
      "预测时间： ['2021-07-16', '2021-07-19', '2021-07-20', '2021-07-21', '2021-07-22', '2021-07-23', '2021-07-26', '2021-07-27', '2021-07-28', '2021-07-29', '2021-07-30', '2021-08-02', '2021-08-03', '2021-08-04', '2021-08-05', '2021-08-06', '2021-08-09', '2021-08-10', '2021-08-11', '2021-08-12', '2021-08-13', '2021-08-16']\n",
      "数据大小： (28094, 294) (1318, 294)\n",
      "y： (28094,) (1318,)\n",
      "get result\n",
      "----- EPOCH 29------\n",
      "预测时间： ['2021-08-17', '2021-08-18', '2021-08-19', '2021-08-20', '2021-08-23', '2021-08-24', '2021-08-25', '2021-08-26', '2021-08-27', '2021-08-30', '2021-08-31', '2021-09-01', '2021-09-02', '2021-09-03', '2021-09-06', '2021-09-07', '2021-09-08', '2021-09-09', '2021-09-10', '2021-09-13', '2021-09-14', '2021-09-15']\n",
      "数据大小： (28189, 294) (1319, 294)\n",
      "y： (28189,) (1319,)\n",
      "get result\n",
      "----- EPOCH 30------\n",
      "预测时间： ['2021-09-16', '2021-09-17', '2021-09-22', '2021-09-23', '2021-09-24', '2021-09-27', '2021-09-28', '2021-09-29', '2021-09-30', '2021-10-08', '2021-10-11', '2021-10-12', '2021-10-13', '2021-10-14', '2021-10-15', '2021-10-18', '2021-10-19', '2021-10-20', '2021-10-21', '2021-10-22', '2021-10-25', '2021-10-26']\n",
      "数据大小： (28277, 294) (1319, 294)\n",
      "y： (28277,) (1319,)\n",
      "get result\n",
      "----- EPOCH 31------\n",
      "预测时间： ['2021-10-27', '2021-10-28', '2021-10-29', '2021-11-01', '2021-11-02', '2021-11-03', '2021-11-04', '2021-11-05', '2021-11-08', '2021-11-09', '2021-11-10', '2021-11-11', '2021-11-12', '2021-11-15', '2021-11-16', '2021-11-17', '2021-11-18', '2021-11-19', '2021-11-22', '2021-11-23', '2021-11-24', '2021-11-25']\n",
      "数据大小： (28366, 294) (1320, 294)\n",
      "y： (28366,) (1320,)\n",
      "get result\n",
      "----- EPOCH 32------\n",
      "预测时间： ['2021-11-26', '2021-11-29', '2021-11-30', '2021-12-01', '2021-12-02', '2021-12-03', '2021-12-06', '2021-12-07', '2021-12-08', '2021-12-09', '2021-12-10', '2021-12-13', '2021-12-14', '2021-12-15', '2021-12-16', '2021-12-17', '2021-12-20', '2021-12-21', '2021-12-22', '2021-12-23', '2021-12-24', '2021-12-27']\n",
      "数据大小： (28458, 294) (1318, 294)\n",
      "y： (28458,) (1318,)\n",
      "get result\n",
      "----- EPOCH 33------\n",
      "预测时间： ['2021-12-28', '2021-12-29', '2021-12-30', '2021-12-31', '2022-01-04', '2022-01-05', '2022-01-06', '2022-01-07', '2022-01-10', '2022-01-11', '2022-01-12', '2022-01-13', '2022-01-14', '2022-01-17', '2022-01-18', '2022-01-19', '2022-01-20', '2022-01-21', '2022-01-24', '2022-01-25', '2022-01-26', '2022-01-27']\n",
      "数据大小： (28545, 294) (1318, 294)\n",
      "y： (28545,) (1318,)\n",
      "get result\n",
      "----- EPOCH 34------\n",
      "预测时间： ['2022-01-28', '2022-02-07', '2022-02-08', '2022-02-09', '2022-02-10', '2022-02-11', '2022-02-14', '2022-02-15', '2022-02-16', '2022-02-17', '2022-02-18', '2022-02-21', '2022-02-22', '2022-02-23', '2022-02-24', '2022-02-25', '2022-02-28', '2022-03-01', '2022-03-02', '2022-03-03', '2022-03-04', '2022-03-07']\n",
      "数据大小： (28632, 294) (1319, 294)\n",
      "y： (28632,) (1319,)\n",
      "get result\n",
      "----- EPOCH 35------\n",
      "预测时间： ['2022-03-08', '2022-03-09', '2022-03-10', '2022-03-11', '2022-03-14', '2022-03-15', '2022-03-16', '2022-03-17', '2022-03-18', '2022-03-21', '2022-03-22', '2022-03-23', '2022-03-24', '2022-03-25', '2022-03-28', '2022-03-29', '2022-03-30', '2022-03-31', '2022-04-01']\n",
      "数据大小： (28712, 294) (1139, 294)\n",
      "y： (28712,) (1139,)\n",
      "get result\n",
      "耗时:822.0465226173401\n",
      "sort values\n",
      "======== COMPLETE LGBMClassifier 0.5333685624325692 ========\n"
     ]
    }
   ],
   "source": [
    "dates = df_500.tradeDate.sort_values().unique()\n",
    "epoch_ts = list(dates)\n",
    "\n",
    "f_index = ['ticker', 'tradeDate']\n",
    "f_x = pickle.load(open(\"pct1_cal/f_x_066\", \"rb\"))\n",
    "label_list = ['PCT5_rank', 'PCT2_rank', 'openclose_pct1_rank', 'askbid_pct1_rank']\n",
    "f_y = 'openclose_pct1_label' #label_list[2]\n",
    "#model_list = ['RidgeR', 'DecisionTreeR', 'XGBoostR', 'LGBMRegressor']\n",
    "model_name = 'LGBMClassifier'#model_list[3]\n",
    "\n",
    "print('======== LEN_TRAIN {} ========'.format(f_y))\n",
    "target_types = ['r', 'c'] # 分类问题还是回归问题 r 回归问题 c 分类问题\n",
    "target_type = target_types[1]\n",
    "\n",
    "result_name = '500_Alter_066_full_{}-{}-{}'.format(model_name, f_y, target_type)\n",
    "print(result_name)\n",
    "\n",
    "update = 22 # 训练长度：22天\n",
    "train_si = epoch_ts.index('2017-01-03') # included. '2017-01-03'\n",
    "train_ei = epoch_ts.index('2019-01-02') # excluded. '2018-12-28'\n",
    "test_si = epoch_ts.index('2019-01-02') # included. '2019-01-02'\n",
    "test_ei = epoch_ts.index('2019-02-01') # excluded. '2019-01-31'\n",
    "test_fi = len(epoch_ts) - 1 # excluded.\n",
    "\n",
    "# number of epochs，循环次数\n",
    "num_epoch = round((test_fi - test_ei) / 22)\n",
    "epoch_range = range(0, num_epoch + 1)\n",
    "#epoch_range = range(0, 1)\n",
    "\n",
    "start = time.time()\n",
    "df_result_all = pd.DataFrame()\n",
    "for epoch in epoch_range:\n",
    "    print('----- EPOCH {}------'.format(epoch))\n",
    "    update_n = epoch * update\n",
    "    # get a list of train dates\n",
    "    epoch_t_train = epoch_ts[train_si + update_n : train_ei + update_n]\n",
    "    # get a list of test dates\n",
    "    epoch_t_test = epoch_ts[test_si + update_n : test_ei + update_n]\n",
    "    df_train = df_500[df_500.tradeDate.apply(lambda x: x in epoch_t_train)].reset_index(drop=True)\n",
    "    df_test = df_500[df_500.tradeDate.apply(lambda x: x in epoch_t_test)].reset_index(drop=True)\n",
    "    print('预测时间：', epoch_t_test)\n",
    "    print('数据大小：', df_train.shape, df_test.shape)\n",
    "\n",
    "    x_train = df_train[f_x].values\n",
    "    x_test = df_test[f_x].values\n",
    "\n",
    "    # 获得y\n",
    "    y_train = df_train[f_y].copy()\n",
    "    y_test = df_test[f_y].copy()\n",
    "    print('y：', y_train.shape, y_test.shape)\n",
    "\n",
    "    model_1 = LogisticRegression(C = 1, solver='liblinear', max_iter = 300)\n",
    "    model_1.fit(x_train, y_train)\n",
    "\n",
    "    #model_2 = lgb.LGBMClassifier(max_depth=5, num_leaves=10, learning_rate=0.05, n_estimators=200)\n",
    "    #model_2.fit(x_train, y_train, eval_set=[(x_train, y_train), (x_test, y_test)], eval_metric='logloss')\n",
    "    y_pred = model_1.predict(x_test)\n",
    "\n",
    "    # 获得结果\n",
    "    print('get result')\n",
    "    df_result = df_test[f_index].copy()\n",
    "    df_result['y'] = y_test\n",
    "    df_result['y_pred'] = y_pred\n",
    "    df_result_all = df_result_all.append(df_result)\n",
    "\n",
    "print(f'耗时:{time.time() - start}') \n",
    "print('sort values')\n",
    "df_result_all = df_result_all.sort_values(by=['ticker', 'tradeDate']).reset_index(drop=True)\n",
    "#today = (datetime.datetime.now()).strftime(\"%Y-%m-%d:%H:%M:%S\")\n",
    "#df_result_all.to_csv('pct1_cal/ZZ500/{}'+today+'.csv'.format(result_name), index=False)\n",
    "score = accuracy_score(df_result_all['y'], df_result_all['y_pred'])\n",
    "print('======== COMPLETE {} {} ========'.format(model_name, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     22739\n",
       "1     22678\n",
       "-1        0\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result_all.y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    23008\n",
       "1    22409\n",
       "Name: y_pred, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result_all.y_pred.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.54      0.54     22739\n",
      "           1       0.53      0.53      0.53     22678\n",
      "\n",
      "    accuracy                           0.53     45417\n",
      "   macro avg       0.53      0.53      0.53     45417\n",
      "weighted avg       0.53      0.53      0.53     45417\n",
      "\n",
      "[[12277 10462]\n",
      " [10731 11947]]\n"
     ]
    }
   ],
   "source": [
    "print( classification_report(df_result_all['y'], df_result_all['y_pred']) )\n",
    "print( confusion_matrix(df_result_all['y'], df_result_all['y_pred']) )\n",
    "plot_roc_curve( model_1, x_test, y_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测时间： ['2019-01-02', '2019-01-03', '2019-01-04', '2019-01-07', '2019-01-08', '2019-01-09', '2019-01-10', '2019-01-11', '2019-01-14', '2019-01-15', '2019-01-16', '2019-01-17', '2019-01-18', '2019-01-21', '2019-01-22', '2019-01-23', '2019-01-24', '2019-01-25', '2019-01-28', '2019-01-29', '2019-01-30', '2019-01-31']\n",
      "数据大小： (24008, 294) (1180, 294)\n",
      "处理后x： (24008, 290) (1180, 290)\n",
      "处理后y： (24008,) (1180,)\n"
     ]
    }
   ],
   "source": [
    "dates = df_500.tradeDate.sort_values().unique()\n",
    "epoch_ts = list(dates)\n",
    "\n",
    "f_index = ['ticker', 'tradeDate']\n",
    "f_x = pickle.load(open(\"pct1_cal/f_x_066\", \"rb\"))\n",
    "f_y = 'openclose_pct1_label' #'openclose_pct1_rank'\n",
    "\n",
    "update = 22 # 训练长度：22天\n",
    "train_si = epoch_ts.index('2017-01-03') # included. '2017-01-03'\n",
    "train_ei = epoch_ts.index('2019-01-02') # excluded. '2018-12-28'\n",
    "test_si = epoch_ts.index('2019-01-02') # included. '2019-01-02'\n",
    "test_ei = epoch_ts.index('2019-02-01') # excluded. '2019-01-31'\n",
    "test_fi = len(epoch_ts) - 1 # excluded.\n",
    "\n",
    "# number of epochs，循环次数\n",
    "num_epoch = round((test_fi - test_ei) / 22)\n",
    "#epoch_range = range(0, num_epoch + 1)\n",
    "#epoch_range = range(0, 1)\n",
    "\n",
    "start = time.time()\n",
    "df_result_all = pd.DataFrame()\n",
    "\n",
    "epoch_t_train = epoch_ts[train_si: train_ei]\n",
    "epoch_t_test = epoch_ts[test_si: test_ei]\n",
    "df_train = df_500[df_500.tradeDate.apply(lambda x: x in epoch_t_train)].reset_index(drop=True)\n",
    "df_test = df_500[df_500.tradeDate.apply(lambda x: x in epoch_t_test)].reset_index(drop=True)\n",
    "print('预测时间：', epoch_t_test)\n",
    "print('数据大小：', df_train.shape, df_test.shape)\n",
    "\n",
    "x_train = df_train[f_x].values\n",
    "x_test = df_test[f_x].values\n",
    "print('处理后x：', x_train.shape, x_test.shape)\n",
    "\n",
    "# 获得y\n",
    "y_train = df_train[f_y].copy()\n",
    "y_test = df_test[f_y].copy()\n",
    "print('处理后y：', y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.56      0.55       591\n",
      "           1       0.54      0.51      0.53       589\n",
      "\n",
      "    accuracy                           0.54      1180\n",
      "   macro avg       0.54      0.54      0.54      1180\n",
      "weighted avg       0.54      0.54      0.54      1180\n",
      "\n",
      "[[333 258]\n",
      " [287 302]]\n"
     ]
    }
   ],
   "source": [
    "model_1 = LogisticRegression(C = 1, solver='liblinear', max_iter = 300)\n",
    "model_1.fit(x_train, y_train)\n",
    "y_pred_1 = model_1.predict(x_test)\n",
    "print( classification_report(y_test, y_pred_1))\n",
    "print( confusion_matrix(y_test, y_pred_1))\n",
    "#plot_roc_curve( model_1, x_test, y_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.60816699 0.54379571 0.67394488 ... 0.58332873 0.56612338 0.46547936]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.03      0.07     12028\n",
      "           1       0.50      0.99      0.67     11980\n",
      "\n",
      "    accuracy                           0.51     24008\n",
      "   macro avg       0.61      0.51      0.37     24008\n",
      "weighted avg       0.61      0.51      0.37     24008\n",
      "\n",
      "[[  416 11612]\n",
      " [  172 11808]]\n"
     ]
    }
   ],
   "source": [
    "y_score_train = model_1.predict_proba(x_train)[:,1]\n",
    "print(y_score_train)\n",
    "thres = 0.3\n",
    "prediction_high_recall_train = (y_score_train > thres).astype(int)\n",
    "print( classification_report(y_train, prediction_high_recall_train))\n",
    "print( confusion_matrix(y_train, prediction_high_recall_train))\n",
    "meta_x_train = np.hstack((prediction_high_recall_train.reshape(-1,1), x_train))\n",
    "meta_y_train = y_train.astype(int) #& prediction_high_recall_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.58391511 0.64599229 0.52987718 ... 0.48654045 0.48755298 0.43106422]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.05      0.09       591\n",
      "           1       0.51      0.98      0.67       589\n",
      "\n",
      "    accuracy                           0.51      1180\n",
      "   macro avg       0.61      0.52      0.38      1180\n",
      "weighted avg       0.61      0.51      0.38      1180\n",
      "\n",
      "[[ 30 561]\n",
      " [ 12 577]]\n"
     ]
    }
   ],
   "source": [
    "y_score_test = model_1.predict_proba(x_test)[:,1]\n",
    "print(y_score_test)\n",
    "thres = 0.3\n",
    "prediction_high_recall_test = (y_score_test > thres).astype(int)\n",
    "print( classification_report(y_test, prediction_high_recall_test ))\n",
    "print( confusion_matrix(y_test, prediction_high_recall_test ))\n",
    "meta_x_test = np.hstack((prediction_high_recall_test .reshape(-1,1), x_test))\n",
    "meta_y_test = y_test.astype(int) #& prediction_high_recall_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.57      0.55       591\n",
      "           1       0.54      0.51      0.53       589\n",
      "\n",
      "    accuracy                           0.54      1180\n",
      "   macro avg       0.54      0.54      0.54      1180\n",
      "weighted avg       0.54      0.54      0.54      1180\n",
      "\n",
      "[[335 256]\n",
      " [287 302]]\n",
      "0.5398305084745763\n"
     ]
    }
   ],
   "source": [
    "model_3 = LogisticRegression(C = 1, solver='liblinear', max_iter = 300)\n",
    "model_3.fit(meta_x_train, meta_y_train)\n",
    "y_pred_3 = model_3.predict(meta_x_test)\n",
    "final_prediction = y_pred_3 & prediction_high_recall_test\n",
    "print( classification_report(meta_y_test, final_prediction))\n",
    "print( confusion_matrix(meta_y_test, final_prediction))\n",
    "print(accuracy_score(meta_y_test, final_prediction))\n",
    "#pd.DataFrame(final_prediction).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's binary_logloss: 0.566613\tvalid_1's binary_logloss: 0.53846\n",
      "[2]\ttraining's binary_logloss: 0.536407\tvalid_1's binary_logloss: 0.511297\n",
      "[3]\ttraining's binary_logloss: 0.510804\tvalid_1's binary_logloss: 0.487847\n",
      "[4]\ttraining's binary_logloss: 0.489056\tvalid_1's binary_logloss: 0.468153\n",
      "[5]\ttraining's binary_logloss: 0.470373\tvalid_1's binary_logloss: 0.451497\n",
      "[6]\ttraining's binary_logloss: 0.454258\tvalid_1's binary_logloss: 0.43745\n",
      "[7]\ttraining's binary_logloss: 0.440255\tvalid_1's binary_logloss: 0.42477\n",
      "[8]\ttraining's binary_logloss: 0.427974\tvalid_1's binary_logloss: 0.413982\n",
      "[9]\ttraining's binary_logloss: 0.41724\tvalid_1's binary_logloss: 0.404434\n",
      "[10]\ttraining's binary_logloss: 0.407797\tvalid_1's binary_logloss: 0.396274\n",
      "[11]\ttraining's binary_logloss: 0.39944\tvalid_1's binary_logloss: 0.388988\n",
      "[12]\ttraining's binary_logloss: 0.392008\tvalid_1's binary_logloss: 0.382932\n",
      "[13]\ttraining's binary_logloss: 0.385478\tvalid_1's binary_logloss: 0.377396\n",
      "[14]\ttraining's binary_logloss: 0.379575\tvalid_1's binary_logloss: 0.37247\n",
      "[15]\ttraining's binary_logloss: 0.374293\tvalid_1's binary_logloss: 0.368256\n",
      "[16]\ttraining's binary_logloss: 0.369534\tvalid_1's binary_logloss: 0.363941\n",
      "[17]\ttraining's binary_logloss: 0.365302\tvalid_1's binary_logloss: 0.360278\n",
      "[18]\ttraining's binary_logloss: 0.361387\tvalid_1's binary_logloss: 0.357095\n",
      "[19]\ttraining's binary_logloss: 0.357943\tvalid_1's binary_logloss: 0.354308\n",
      "[20]\ttraining's binary_logloss: 0.354742\tvalid_1's binary_logloss: 0.351802\n",
      "[21]\ttraining's binary_logloss: 0.351847\tvalid_1's binary_logloss: 0.349165\n",
      "[22]\ttraining's binary_logloss: 0.349161\tvalid_1's binary_logloss: 0.347181\n",
      "[23]\ttraining's binary_logloss: 0.346719\tvalid_1's binary_logloss: 0.345529\n",
      "[24]\ttraining's binary_logloss: 0.344589\tvalid_1's binary_logloss: 0.343916\n",
      "[25]\ttraining's binary_logloss: 0.342637\tvalid_1's binary_logloss: 0.342318\n",
      "[26]\ttraining's binary_logloss: 0.340864\tvalid_1's binary_logloss: 0.340468\n",
      "[27]\ttraining's binary_logloss: 0.339132\tvalid_1's binary_logloss: 0.339662\n",
      "[28]\ttraining's binary_logloss: 0.337573\tvalid_1's binary_logloss: 0.338175\n",
      "[29]\ttraining's binary_logloss: 0.336108\tvalid_1's binary_logloss: 0.33698\n",
      "[30]\ttraining's binary_logloss: 0.334725\tvalid_1's binary_logloss: 0.336152\n",
      "[31]\ttraining's binary_logloss: 0.333393\tvalid_1's binary_logloss: 0.335437\n",
      "[32]\ttraining's binary_logloss: 0.332231\tvalid_1's binary_logloss: 0.334839\n",
      "[33]\ttraining's binary_logloss: 0.331113\tvalid_1's binary_logloss: 0.333861\n",
      "[34]\ttraining's binary_logloss: 0.330083\tvalid_1's binary_logloss: 0.333354\n",
      "[35]\ttraining's binary_logloss: 0.329153\tvalid_1's binary_logloss: 0.332488\n",
      "[36]\ttraining's binary_logloss: 0.328167\tvalid_1's binary_logloss: 0.331586\n",
      "[37]\ttraining's binary_logloss: 0.327272\tvalid_1's binary_logloss: 0.331079\n",
      "[38]\ttraining's binary_logloss: 0.326484\tvalid_1's binary_logloss: 0.330092\n",
      "[39]\ttraining's binary_logloss: 0.325638\tvalid_1's binary_logloss: 0.329742\n",
      "[40]\ttraining's binary_logloss: 0.325063\tvalid_1's binary_logloss: 0.329463\n",
      "[41]\ttraining's binary_logloss: 0.324382\tvalid_1's binary_logloss: 0.329034\n",
      "[42]\ttraining's binary_logloss: 0.323791\tvalid_1's binary_logloss: 0.32889\n",
      "[43]\ttraining's binary_logloss: 0.323189\tvalid_1's binary_logloss: 0.328627\n",
      "[44]\ttraining's binary_logloss: 0.322675\tvalid_1's binary_logloss: 0.328438\n",
      "[45]\ttraining's binary_logloss: 0.322098\tvalid_1's binary_logloss: 0.328335\n",
      "[46]\ttraining's binary_logloss: 0.321574\tvalid_1's binary_logloss: 0.327877\n",
      "[47]\ttraining's binary_logloss: 0.321023\tvalid_1's binary_logloss: 0.327749\n",
      "[48]\ttraining's binary_logloss: 0.320541\tvalid_1's binary_logloss: 0.327528\n",
      "[49]\ttraining's binary_logloss: 0.320081\tvalid_1's binary_logloss: 0.327554\n",
      "[50]\ttraining's binary_logloss: 0.319625\tvalid_1's binary_logloss: 0.327341\n",
      "[51]\ttraining's binary_logloss: 0.319283\tvalid_1's binary_logloss: 0.327373\n",
      "[52]\ttraining's binary_logloss: 0.318843\tvalid_1's binary_logloss: 0.327353\n",
      "[53]\ttraining's binary_logloss: 0.318331\tvalid_1's binary_logloss: 0.327408\n",
      "[54]\ttraining's binary_logloss: 0.317952\tvalid_1's binary_logloss: 0.327451\n",
      "[55]\ttraining's binary_logloss: 0.317502\tvalid_1's binary_logloss: 0.32736\n",
      "[56]\ttraining's binary_logloss: 0.317154\tvalid_1's binary_logloss: 0.327354\n",
      "[57]\ttraining's binary_logloss: 0.316808\tvalid_1's binary_logloss: 0.327006\n",
      "[58]\ttraining's binary_logloss: 0.316364\tvalid_1's binary_logloss: 0.326829\n",
      "[59]\ttraining's binary_logloss: 0.315958\tvalid_1's binary_logloss: 0.326766\n",
      "[60]\ttraining's binary_logloss: 0.315631\tvalid_1's binary_logloss: 0.326523\n",
      "[61]\ttraining's binary_logloss: 0.315263\tvalid_1's binary_logloss: 0.326347\n",
      "[62]\ttraining's binary_logloss: 0.315\tvalid_1's binary_logloss: 0.326208\n",
      "[63]\ttraining's binary_logloss: 0.314734\tvalid_1's binary_logloss: 0.326175\n",
      "[64]\ttraining's binary_logloss: 0.314361\tvalid_1's binary_logloss: 0.326125\n",
      "[65]\ttraining's binary_logloss: 0.314044\tvalid_1's binary_logloss: 0.326272\n",
      "[66]\ttraining's binary_logloss: 0.313668\tvalid_1's binary_logloss: 0.326104\n",
      "[67]\ttraining's binary_logloss: 0.313388\tvalid_1's binary_logloss: 0.326148\n",
      "[68]\ttraining's binary_logloss: 0.313052\tvalid_1's binary_logloss: 0.32608\n",
      "[69]\ttraining's binary_logloss: 0.312765\tvalid_1's binary_logloss: 0.326207\n",
      "[70]\ttraining's binary_logloss: 0.312453\tvalid_1's binary_logloss: 0.326072\n",
      "[71]\ttraining's binary_logloss: 0.312122\tvalid_1's binary_logloss: 0.326098\n",
      "[72]\ttraining's binary_logloss: 0.311762\tvalid_1's binary_logloss: 0.325948\n",
      "[73]\ttraining's binary_logloss: 0.311442\tvalid_1's binary_logloss: 0.326095\n",
      "[74]\ttraining's binary_logloss: 0.311074\tvalid_1's binary_logloss: 0.326005\n",
      "[75]\ttraining's binary_logloss: 0.310689\tvalid_1's binary_logloss: 0.325787\n",
      "[76]\ttraining's binary_logloss: 0.310337\tvalid_1's binary_logloss: 0.325829\n",
      "[77]\ttraining's binary_logloss: 0.309984\tvalid_1's binary_logloss: 0.326103\n",
      "[78]\ttraining's binary_logloss: 0.309588\tvalid_1's binary_logloss: 0.325841\n",
      "[79]\ttraining's binary_logloss: 0.309242\tvalid_1's binary_logloss: 0.325768\n",
      "[80]\ttraining's binary_logloss: 0.30897\tvalid_1's binary_logloss: 0.325741\n",
      "[81]\ttraining's binary_logloss: 0.308663\tvalid_1's binary_logloss: 0.325314\n",
      "[82]\ttraining's binary_logloss: 0.308369\tvalid_1's binary_logloss: 0.324805\n",
      "[83]\ttraining's binary_logloss: 0.308095\tvalid_1's binary_logloss: 0.324844\n",
      "[84]\ttraining's binary_logloss: 0.30783\tvalid_1's binary_logloss: 0.324698\n",
      "[85]\ttraining's binary_logloss: 0.307441\tvalid_1's binary_logloss: 0.324573\n",
      "[86]\ttraining's binary_logloss: 0.307142\tvalid_1's binary_logloss: 0.324316\n",
      "[87]\ttraining's binary_logloss: 0.306785\tvalid_1's binary_logloss: 0.32444\n",
      "[88]\ttraining's binary_logloss: 0.306445\tvalid_1's binary_logloss: 0.32449\n",
      "[89]\ttraining's binary_logloss: 0.306072\tvalid_1's binary_logloss: 0.324591\n",
      "[90]\ttraining's binary_logloss: 0.305802\tvalid_1's binary_logloss: 0.324567\n",
      "[91]\ttraining's binary_logloss: 0.305532\tvalid_1's binary_logloss: 0.324422\n",
      "[92]\ttraining's binary_logloss: 0.305264\tvalid_1's binary_logloss: 0.324518\n",
      "[93]\ttraining's binary_logloss: 0.305006\tvalid_1's binary_logloss: 0.324524\n",
      "[94]\ttraining's binary_logloss: 0.304748\tvalid_1's binary_logloss: 0.32461\n",
      "[95]\ttraining's binary_logloss: 0.304382\tvalid_1's binary_logloss: 0.32437\n",
      "[96]\ttraining's binary_logloss: 0.304053\tvalid_1's binary_logloss: 0.324251\n",
      "[97]\ttraining's binary_logloss: 0.303774\tvalid_1's binary_logloss: 0.324163\n",
      "[98]\ttraining's binary_logloss: 0.303436\tvalid_1's binary_logloss: 0.324385\n",
      "[99]\ttraining's binary_logloss: 0.303138\tvalid_1's binary_logloss: 0.324835\n",
      "[100]\ttraining's binary_logloss: 0.302819\tvalid_1's binary_logloss: 0.324779\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.63      0.58       591\n",
      "           1       0.56      0.47      0.51       589\n",
      "\n",
      "    accuracy                           0.55      1180\n",
      "   macro avg       0.55      0.55      0.55      1180\n",
      "weighted avg       0.55      0.55      0.55      1180\n",
      "\n",
      "[[370 221]\n",
      " [310 279]]\n",
      "0.7932203389830509\n"
     ]
    }
   ],
   "source": [
    "model_2 = lgb.LGBMClassifier(max_depth=5, num_leaves=10, learning_rate=0.09, n_estimators=100)\n",
    "model_2.fit(meta_x_train, meta_y_train, eval_set=[(meta_x_train, meta_y_train), (meta_x_test, meta_y_test)], eval_metric='logloss')\n",
    "meta_y_pred = model_2.predict(meta_x_test)\n",
    "final_prediction = meta_y_pred & prediction_high_recall_test\n",
    "print( classification_report(y_test, final_prediction))\n",
    "print( confusion_matrix(y_test, final_prediction))\n",
    "print(accuracy_score(meta_y_test, final_prediction))\n",
    "#pd.DataFrame(final_prediction).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "def build_model_1(x_train, y_train):\n",
    "    \n",
    "    logitreg_parameters = {'C': np.power(10.0, np.arange(-9, 1))}\n",
    "    \n",
    "    model_1 = LogisticRegression(solver='liblinear', max_iter = 300)\n",
    "    logitreg_grid = GridSearchCV(model_1, param_grid = logitreg_parameters,scoring = 'f1', n_jobs = 1, cv=5)          \n",
    "                             \n",
    "    logitreg_grid.fit(x_train, y_train)\n",
    "    \n",
    "    return logitreg_grid\n",
    "model_1 = build_model_1(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        'C': trial.suggest_float('C', np.power(10.0, -9), np.power(10.0, 1)),\n",
    "        #'solver' : trial.suggest_categorical('solver', ['lbfgs', 'liblinear'])\n",
    "        #\"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 1000),\n",
    "        #\"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.15),\n",
    "    }\n",
    "    # 'n_estimators': [20], 'max_depth': [3], 'max_features': [10], 'subsample': [1.0]},\n",
    "    # 'splitter': ['random'], 'criterion': ['friedman_mse'], 'max_depth': [6], \n",
    "    # 'min_samples_leaf': [41], 'min_impurity_decrease': [0.5]\n",
    "    cv = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "    cv_scores = np.empty(3)\n",
    "\n",
    "    # LGBM\n",
    "    for idx, (train_idx, test_idx) in enumerate(cv.split(df_train[f_x], df_train[f_y])):\n",
    "        x_cv_train, x_cv_test = df_train[f_x].iloc[train_idx], df_train[f_x].iloc[test_idx]\n",
    "        y_cv_train, y_cv_test = df_train[f_y][train_idx], df_train[f_y][test_idx]\n",
    "\n",
    "        model = LogisticRegression(solver= 'liblinear', **params)\n",
    "        model.fit(x_cv_train, y_cv_train)\n",
    "        #model = lgb.LGBMClassifier(max_depth=5, num_leaves=10, **params)\n",
    "        #model.fit(x_cv_train, y_cv_train, eval_set=[(x_cv_train, y_cv_train), \\\n",
    "        #    (x_cv_test, y_cv_test)], eval_metric='logloss')\n",
    "        y_pred = model.predict(x_cv_test)\n",
    "\n",
    "            # 获得结果\n",
    "        #df_result = pd.DataFrame({'y' : y_test, 'y_pred': y_pred})\n",
    "        #IC = df_result[['y', 'y_pred']].corr().iloc[0,1]\n",
    "        cv_scores[idx] = accuracy_score(y_cv_test, y_pred)\n",
    "    return np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-28 17:30:09,414]\u001b[0m A new study created in memory with name: no-name-8849177e-a2d5-4f41-96eb-f41b82db29b4\u001b[0m\n",
      "/workspace1/liufengyuan/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/workspace1/liufengyuan/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/workspace1/liufengyuan/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "\u001b[32m[I 2022-06-28 17:30:11,818]\u001b[0m Trial 0 finished with value: 0.5468732644673997 and parameters: {'C': 6.779758228964663, 'solver': 'lbfgs'}. Best is trial 0 with value: 0.5468732644673997.\u001b[0m\n",
      "/workspace1/liufengyuan/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/workspace1/liufengyuan/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/workspace1/liufengyuan/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "\u001b[32m[I 2022-06-28 17:30:14,633]\u001b[0m Trial 1 finished with value: 0.5487059868932578 and parameters: {'C': 3.4583072472623204, 'solver': 'lbfgs'}. Best is trial 1 with value: 0.5487059868932578.\u001b[0m\n",
      "/workspace1/liufengyuan/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/workspace1/liufengyuan/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/workspace1/liufengyuan/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "\u001b[32m[I 2022-06-28 17:30:17,757]\u001b[0m Trial 2 finished with value: 0.5476507830723092 and parameters: {'C': 8.763369562035352, 'solver': 'lbfgs'}. Best is trial 1 with value: 0.5487059868932578.\u001b[0m\n",
      "\u001b[32m[I 2022-06-28 17:30:43,034]\u001b[0m Trial 3 finished with value: 0.5501499500166611 and parameters: {'C': 2.4064785701231046, 'solver': 'liblinear'}. Best is trial 3 with value: 0.5501499500166611.\u001b[0m\n",
      "/workspace1/liufengyuan/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/workspace1/liufengyuan/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/workspace1/liufengyuan/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "\u001b[32m[I 2022-06-28 17:30:46,210]\u001b[0m Trial 4 finished with value: 0.5474286348994779 and parameters: {'C': 2.4350401327827944, 'solver': 'lbfgs'}. Best is trial 3 with value: 0.5501499500166611.\u001b[0m\n",
      "\u001b[32m[I 2022-06-28 17:31:23,917]\u001b[0m Trial 5 finished with value: 0.5513162279240253 and parameters: {'C': 7.260857407782794, 'solver': 'liblinear'}. Best is trial 5 with value: 0.5513162279240253.\u001b[0m\n",
      "\u001b[32m[I 2022-06-28 17:31:49,917]\u001b[0m Trial 6 finished with value: 0.5499833388870377 and parameters: {'C': 2.6262277414308737, 'solver': 'liblinear'}. Best is trial 5 with value: 0.5513162279240253.\u001b[0m\n",
      "/workspace1/liufengyuan/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/workspace1/liufengyuan/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/workspace1/liufengyuan/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "\u001b[32m[I 2022-06-28 17:31:52,688]\u001b[0m Trial 7 finished with value: 0.5475397089858935 and parameters: {'C': 5.98111508076307, 'solver': 'lbfgs'}. Best is trial 5 with value: 0.5513162279240253.\u001b[0m\n",
      "\u001b[32m[I 2022-06-28 17:32:18,071]\u001b[0m Trial 8 finished with value: 0.550816394535155 and parameters: {'C': 1.619514543789714, 'solver': 'liblinear'}. Best is trial 5 with value: 0.5513162279240253.\u001b[0m\n",
      "/workspace1/liufengyuan/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/workspace1/liufengyuan/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/workspace1/liufengyuan/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "\u001b[32m[I 2022-06-28 17:32:20,673]\u001b[0m Trial 9 finished with value: 0.5477618571587248 and parameters: {'C': 3.059068527905002, 'solver': 'lbfgs'}. Best is trial 5 with value: 0.5513162279240253.\u001b[0m\n",
      "\u001b[32m[I 2022-06-28 17:32:59,216]\u001b[0m Trial 10 finished with value: 0.5517605242696879 and parameters: {'C': 9.112076810113889, 'solver': 'liblinear'}. Best is trial 10 with value: 0.5517605242696879.\u001b[0m\n",
      "\u001b[32m[I 2022-06-28 17:33:40,126]\u001b[0m Trial 11 finished with value: 0.5518715983561036 and parameters: {'C': 9.444142694841194, 'solver': 'liblinear'}. Best is trial 11 with value: 0.5518715983561036.\u001b[0m\n",
      "\u001b[32m[I 2022-06-28 17:34:17,510]\u001b[0m Trial 12 finished with value: 0.5519271353993114 and parameters: {'C': 9.515158726133656, 'solver': 'liblinear'}. Best is trial 12 with value: 0.5519271353993114.\u001b[0m\n",
      "\u001b[32m[I 2022-06-28 17:34:59,155]\u001b[0m Trial 13 finished with value: 0.5518160613128957 and parameters: {'C': 9.60539520525797, 'solver': 'liblinear'}. Best is trial 12 with value: 0.5519271353993114.\u001b[0m\n",
      "\u001b[32m[I 2022-06-28 17:35:38,258]\u001b[0m Trial 14 finished with value: 0.5512051538376097 and parameters: {'C': 7.782858451422969, 'solver': 'liblinear'}. Best is trial 12 with value: 0.5519271353993114.\u001b[0m\n",
      "\u001b[32m[I 2022-06-28 17:35:50,560]\u001b[0m Trial 15 finished with value: 0.5503720981894924 and parameters: {'C': 0.16628683525962185, 'solver': 'liblinear'}. Best is trial 12 with value: 0.5519271353993114.\u001b[0m\n",
      "\u001b[32m[I 2022-06-28 17:36:27,931]\u001b[0m Trial 16 finished with value: 0.5509830056647784 and parameters: {'C': 5.265799340862678, 'solver': 'liblinear'}. Best is trial 12 with value: 0.5519271353993114.\u001b[0m\n",
      "\u001b[32m[I 2022-06-28 17:37:04,885]\u001b[0m Trial 17 finished with value: 0.5515939131400645 and parameters: {'C': 8.570933987483066, 'solver': 'liblinear'}. Best is trial 12 with value: 0.5519271353993114.\u001b[0m\n",
      "\u001b[32m[I 2022-06-28 17:37:46,256]\u001b[0m Trial 18 finished with value: 0.5519271353993114 and parameters: {'C': 9.934944833038971, 'solver': 'liblinear'}. Best is trial 12 with value: 0.5519271353993114.\u001b[0m\n",
      "\u001b[32m[I 2022-06-28 17:38:21,499]\u001b[0m Trial 19 finished with value: 0.5512606908808175 and parameters: {'C': 4.21719135292032, 'solver': 'liblinear'}. Best is trial 12 with value: 0.5519271353993114.\u001b[0m\n",
      "\u001b[32m[I 2022-06-28 17:39:00,363]\u001b[0m Trial 20 finished with value: 0.5514828390536488 and parameters: {'C': 7.989375979582152, 'solver': 'liblinear'}. Best is trial 12 with value: 0.5519271353993114.\u001b[0m\n",
      "\u001b[32m[I 2022-06-28 17:39:42,338]\u001b[0m Trial 21 finished with value: 0.5518160613128957 and parameters: {'C': 9.913993092828457, 'solver': 'liblinear'}. Best is trial 12 with value: 0.5519271353993114.\u001b[0m\n",
      "\u001b[32m[I 2022-06-28 17:40:21,775]\u001b[0m Trial 22 finished with value: 0.5518160613128957 and parameters: {'C': 9.841112545502877, 'solver': 'liblinear'}. Best is trial 12 with value: 0.5519271353993114.\u001b[0m\n",
      "\u001b[32m[I 2022-06-28 17:40:55,586]\u001b[0m Trial 23 finished with value: 0.5510940797511941 and parameters: {'C': 6.532357645666132, 'solver': 'liblinear'}. Best is trial 12 with value: 0.5519271353993114.\u001b[0m\n",
      "\u001b[32m[I 2022-06-28 17:41:36,051]\u001b[0m Trial 24 finished with value: 0.5516494501832723 and parameters: {'C': 8.235866907314504, 'solver': 'liblinear'}. Best is trial 12 with value: 0.5519271353993114.\u001b[0m\n",
      "\u001b[32m[I 2022-06-28 17:42:15,554]\u001b[0m Trial 25 finished with value: 0.5517049872264801 and parameters: {'C': 9.109742314011026, 'solver': 'liblinear'}. Best is trial 12 with value: 0.5519271353993114.\u001b[0m\n",
      "\u001b[32m[I 2022-06-28 17:42:58,686]\u001b[0m Trial 26 finished with value: 0.5512051538376097 and parameters: {'C': 7.474901113955559, 'solver': 'liblinear'}. Best is trial 12 with value: 0.5519271353993114.\u001b[0m\n",
      "\u001b[32m[I 2022-06-28 17:43:35,501]\u001b[0m Trial 27 finished with value: 0.5518715983561036 and parameters: {'C': 9.337034149545303, 'solver': 'liblinear'}. Best is trial 12 with value: 0.5519271353993114.\u001b[0m\n",
      "\u001b[32m[I 2022-06-28 17:44:11,518]\u001b[0m Trial 28 finished with value: 0.5507608574919471 and parameters: {'C': 5.767486330058963, 'solver': 'liblinear'}. Best is trial 12 with value: 0.5519271353993114.\u001b[0m\n",
      "/workspace1/liufengyuan/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/workspace1/liufengyuan/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/workspace1/liufengyuan/.local/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "\u001b[32m[I 2022-06-28 17:44:15,492]\u001b[0m Trial 29 finished with value: 0.5472620237698544 and parameters: {'C': 7.202897121187901, 'solver': 'lbfgs'}. Best is trial 12 with value: 0.5519271353993114.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgb.LGBMClassifier(max_depth=5, num_leaves=10, learning_rate=0.09, n_estimators=100)\n",
    "model.fit(x_train, y_train, eval_set=[(x_train, y_train), \\\n",
    "    (x_test, y_test)], eval_metric='logloss')\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "    # 获得结果\n",
    "#df_result = pd.DataFrame({'y' : y_test, 'y_pred': y_pred})\n",
    "#IC = df_result[['y', 'y_pred']].corr().iloc[0,1]\n",
    "accuracy_score(y_test, y_pred)\n",
    "# 200: 0.89985, 0.09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame(index=df_train.index)\n",
    "df_result['y'] = y_test\n",
    "df_result['y_pred'] = y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0c4e795b307436e90878d87b7b6ea0f9ae1f8d88c9c1ffc8ae37ae0851c943d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
