{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UQER SDK的DataAPI模块版本由84.0.72升级到84.0.82\n",
      "127807@wmcloud.com 账号登录成功\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import time\n",
    "import uqer\n",
    "import pickle\n",
    "import datetime\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from uqer import DataAPI   #优矿api\n",
    "from sklearn import linear_model\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import Ridge, LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "\n",
    "client = uqer.Client(token='18266a7c0ac9f8cdbe00f9b2ecb65f42316a5f78d9cc22ebabcbd923593356e4')\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ticekrToStr(job_sum):\n",
    "    job_sum = job_sum[job_sum.ticker<700000]\n",
    "    job_sum.loc[job_sum.ticker<10,'temp']='00000'\n",
    "    job_sum.loc[(job_sum.ticker<100)&(job_sum.ticker>=10),'temp']='0000'\n",
    "    job_sum.loc[(job_sum.ticker<1000)&(job_sum.ticker>=100),'temp']='000'\n",
    "    job_sum.loc[(job_sum.ticker<10000)&(job_sum.ticker>=1000),'temp']='00'\n",
    "    job_sum.loc[job_sum.temp==job_sum.temp,'ticker'] = job_sum[job_sum.temp==job_sum.temp]['temp']+job_sum[job_sum.temp==job_sum.temp]['ticker'].astype(str)\n",
    "    del job_sum['temp']\n",
    "    job_sum['ticker'] = job_sum['ticker'].astype(str)\n",
    "    return job_sum\n",
    "\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deal with raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_location = '/data/liufengyuan/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####alpha####\n",
    "path1 = file_location + 'raw_data/alphas_036'\n",
    "filenames = glob.glob(path1 + '/*.csv')\n",
    "result_list = []\n",
    "for file in filenames:\n",
    "    name = file[38:-4]\n",
    "    print(name)\n",
    "    alpha = pd.read_csv(file)\n",
    "    alpha = alpha.rename(columns={\"date\": \"tradeDate\"})\n",
    "    alpha = alpha.set_index(['tradeDate']).stack().reset_index().rename(columns={'level_1': 'ticker', 0: name})\n",
    "    alpha['ticker'] = alpha['ticker'].astype(int)\n",
    "    alpha = alpha.set_index(['ticker', 'tradeDate'])\n",
    "    alpha = alpha.sort_index(ascending=True)\n",
    "    result_list.append(alpha)\n",
    "result = pd.concat(result_list, axis=1)\n",
    "result.to_csv(file_location + 'pct5_cal/alphas_036.csv')\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####alternative####\n",
    "alter = pd.read_csv(file_location + 'raw_data/alternative_factors.csv')\n",
    "alter = alter.iloc[:, 1:]\n",
    "print(alter.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####combine alternative+alpha####\n",
    "alpha = result.reset_index()\n",
    "alter = alter.merge(alpha, on=['ticker', 'tradeDate'], how='left')\n",
    "del result\n",
    "del alpha\n",
    "print(alter.shape)\n",
    "alter = alter.dropna(thresh = 87)\n",
    "alter = reduce_mem_usage(alter)\n",
    "f_x_066 = alter.columns.values.tolist()[2:]\n",
    "print(alter.shape)\n",
    "print(f_x_066)\n",
    "pickle.dump(f_x_066, open(file_location + \"pct5_cal/f_x_036\", \"wb\"))\n",
    "alter.to_csv(file_location + 'pct5_cal/1alter_alphas_036.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ticker</th>\n",
       "      <th>tradeDate</th>\n",
       "      <th>PCT5</th>\n",
       "      <th>PCT5_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-03</td>\n",
       "      <td>-0.001201</td>\n",
       "      <td>0.566613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>-0.001418</td>\n",
       "      <td>0.723032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>0.002189</td>\n",
       "      <td>0.869945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>-0.002079</td>\n",
       "      <td>0.870394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-09</td>\n",
       "      <td>-0.001967</td>\n",
       "      <td>0.873344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5017053</th>\n",
       "      <td>5046061</td>\n",
       "      <td>689009</td>\n",
       "      <td>2022-05-10</td>\n",
       "      <td>0.126496</td>\n",
       "      <td>0.968439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5017054</th>\n",
       "      <td>5046062</td>\n",
       "      <td>689009</td>\n",
       "      <td>2022-05-11</td>\n",
       "      <td>0.163312</td>\n",
       "      <td>0.974793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5017055</th>\n",
       "      <td>5046063</td>\n",
       "      <td>689009</td>\n",
       "      <td>2022-05-12</td>\n",
       "      <td>0.232190</td>\n",
       "      <td>0.989411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5017056</th>\n",
       "      <td>5046064</td>\n",
       "      <td>689009</td>\n",
       "      <td>2022-05-13</td>\n",
       "      <td>0.181071</td>\n",
       "      <td>0.976069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5017057</th>\n",
       "      <td>5046065</td>\n",
       "      <td>689009</td>\n",
       "      <td>2022-05-16</td>\n",
       "      <td>0.114978</td>\n",
       "      <td>0.934520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5017058 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0  ticker   tradeDate      PCT5  PCT5_rank\n",
       "0                 0       1  2017-01-03 -0.001201   0.566613\n",
       "1                 1       1  2017-01-04 -0.001418   0.723032\n",
       "2                 2       1  2017-01-05  0.002189   0.869945\n",
       "3                 3       1  2017-01-06 -0.002079   0.870394\n",
       "4                 4       1  2017-01-09 -0.001967   0.873344\n",
       "...             ...     ...         ...       ...        ...\n",
       "5017053     5046061  689009  2022-05-10  0.126496   0.968439\n",
       "5017054     5046062  689009  2022-05-11  0.163312   0.974793\n",
       "5017055     5046063  689009  2022-05-12  0.232190   0.989411\n",
       "5017056     5046064  689009  2022-05-13  0.181071   0.976069\n",
       "5017057     5046065  689009  2022-05-16  0.114978   0.934520\n",
       "\n",
       "[5017058 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(file_location + 'labels/PCT5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'label_vwap_pct1_full.csv'\n",
    "name = file[6:-4]\n",
    "print(name)\n",
    "label = name + '_rank'\n",
    "alpha = pd.read_csv('raw_data/' + file)\n",
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = alpha.loc[alpha['tradeDate'] >= '2017-01-03']\n",
    "#alpha = alpha.rename(columns = lambda x: x[:-5] if (x != 'date') else 'tradeDate')\n",
    "alpha = alpha.set_index(['tradeDate']).stack().reset_index().rename(columns={'level_1': 'ticker', 0: name})\n",
    "alpha['ticker'] = alpha['ticker'].astype(int)\n",
    "alpha = alpha.sort_values(by=['ticker', 'tradeDate']).reset_index(drop=True)\n",
    "alpha[label] = alpha.groupby('tradeDate')[name].rank(pct = True)\n",
    "alpha.to_csv('labels/{}.csv'.format(name), index=False)\n",
    "print('----- Finished FILE {}------'.format(file))\n",
    "alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uqer Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target(ticker_name):\n",
    "    # get close price and market value\n",
    "    outData = DataAPI.MktEqudGet(ticker=ticker_name, beginDate='2017-07-25', endDate='2022-04-05', pandas=\"1\")\n",
    "    outData = outData[['ticker', 'tradeDate', 'closePrice', 'marketValue']]\n",
    "    # get industry\n",
    "    industry_data = DataAPI.EquIndustryGet(ticker=ticker_name, pandas=\"1\")\n",
    "    industry_name = industry_data.at[0, 'industryName1']\n",
    "    # get listDate\n",
    "    list_date = DataAPI.EquGet(ticker=ticker_name ,pandas=\"1\")\n",
    "    list_date = list_date.at[0, 'listDate']\n",
    "    # combine data\n",
    "    outData['industry'] = industry_name\n",
    "    outData['listData'] = list_date\n",
    "    outData = outData.sort_values(by=['tradeDate']).reset_index(drop=True)\n",
    "    return outData[['ticker', 'tradeDate', 'marketValue', 'industry', 'listData']]\n",
    "\n",
    "print('load data')\n",
    "data = pd.read_csv(file_location + 'pct5_cal/1alter_alphas_036.csv', usecols=['ticker'])\n",
    "print(data)\n",
    "strData = ticekrToStr(data)\n",
    "tickers = strData.ticker.unique()\n",
    "tickers = tickers.tolist()\n",
    "\n",
    "df_merge = get_target(tickers)\n",
    "print('sort values')\n",
    "df_merge = df_merge.sort_values(by=['ticker', 'tradeDate']).reset_index(drop=True)\n",
    "print(df_merge)\n",
    "df_merge.to_csv(file_location + 'pct1_cal/3uqer_data.csv', index = False)\n",
    "\n",
    "df_merge.industry = df_merge.industry.fillna('其他')\n",
    "industry_to_number = {}\n",
    "for i, v in enumerate(df_merge.industry.sort_values().unique()):\n",
    "    industry_to_number[v] = i+1\n",
    "print(industry_to_number)\n",
    "df_merge.industry = df_merge.industry.map(industry_to_number)\n",
    "df_idst = pd.get_dummies(df_merge.industry, prefix='idst')\n",
    "df = df_merge.merge(df_idst, left_index=True, right_index=True)\n",
    "df['log_marketValue'] = df.marketValue.apply(np.log)\n",
    "df.to_csv(file_location + 'pct5_cal/4uqer_idst_log.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('========LOADING AND COMBINING ALTER DATA========')\n",
    "alpha = pd.read_csv('pct1_cal/alphas_066.csv')\n",
    "print(alpha.shape)\n",
    "print('========COMPLETE LOADING AND COMBINING ALTER DATA========')\n",
    "\n",
    "print('========LOADING ALTER DATA========')\n",
    "alter = pd.read_csv('raw_data/alternative_factors.csv')\n",
    "alter = alter.iloc[:, 1:]\n",
    "print(alter.shape)\n",
    "print('========COMPLETE LOADING ALTER DATA========')\n",
    "\n",
    "print('========COMBINING ALTER ALPHA DATA========')\n",
    "alter = alter.merge(alpha, on=['ticker', 'tradeDate'], how='left')\n",
    "del alpha\n",
    "print(alter.shape)\n",
    "print('========COMPLETE COMBINING ALTER ALPHA DATA========')\n",
    "\n",
    "print('========REALLOCATE ALTER ALPHA DATA========')\n",
    "alter = alter.dropna(thresh = 87)\n",
    "alter = reduce_mem_usage(alter)\n",
    "print(alter)\n",
    "f_x_066 = alter.columns.values.tolist()[2:]\n",
    "print(f_x_066)\n",
    "pickle.dump(f_x_066, open(\"pct1_cal/f_x_066\", \"wb\"))\n",
    "print('store alphas 222')\n",
    "alter.to_csv('pct1_cal/1alter_alphas_066.csv', index = False)\n",
    "print('========COMPLETE STORING ALTER ALPHAS 066========')\n",
    "\n",
    "#alter = pd.read_csv('pct1_cal/1alter_alphas_066.csv')\n",
    "\n",
    "print('========LOADING UQER DATA========')\n",
    "uqer_data = pd.read_csv('pct1_cal/4uqer_idst_log.csv')\n",
    "print(uqer_data.shape)\n",
    "print('========COMPLETE LOADING UQER DATA========')\n",
    "\n",
    "print('========COMBINE ALTER ALPHA UQER DATA========')\n",
    "alter = alter.merge(uqer_data, on=['ticker', 'tradeDate'], how='left')\n",
    "alter = alter[~alter.log_marketValue.isnull()]\n",
    "print(alter.shape)\n",
    "del uqer_data\n",
    "alter = reduce_mem_usage(alter)\n",
    "print('========COMPLETE COMBINE ALTER ALPHA UQER DATA========')\n",
    "\n",
    "print('get column lists')\n",
    "f_index = ['ticker', 'tradeDate']\n",
    "f_industry = pickle.load(open(\"pct1_cal/f_industry\", \"rb\"))\n",
    "f_x = pickle.load(open(\"pct1_cal/f_x_066\", \"rb\"))\n",
    "label_list = ['askbid_pct1_rank', 'openclose_pct1_rank']\n",
    "\n",
    "print('========COMBINING LABEL DATA========')\n",
    "path2 = 'labels'\n",
    "filenames = glob.glob(path2 + '/*pct1.csv')\n",
    "for file in filenames:\n",
    "    print(file)\n",
    "    label = pd.read_csv(file)\n",
    "    label_name = label.columns.values.tolist()[-1]\n",
    "    label = label[['ticker', 'tradeDate', label_name]]\n",
    "    alter = alter.merge(label, on=['ticker', 'tradeDate'], how='left')\n",
    "    del label\n",
    "alter = reduce_mem_usage(alter)\n",
    "print(alter.shape)\n",
    "print('========COMPLETE COMBINING LABEL DATA========')\n",
    "\n",
    "print('store raw data')\n",
    "alter.to_csv('pct1_cal/alter_idst_alphas_066_labels_raw.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0c4e795b307436e90878d87b7b6ea0f9ae1f8d88c9c1ffc8ae37ae0851c943d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
